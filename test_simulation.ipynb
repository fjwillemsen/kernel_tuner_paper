{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Tuner Simulation Mode Test\n",
    "\n",
    "This notebook is intended to examine the completeness, consistency, and advantage of simulation mode in Kernel Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "\n",
    "cachedirectory = Path(\"kernels/outputdata/simulation_mode\")\n",
    "savedirectory = Path(Path.cwd(), \"figures\", \"simulation_mode\")\n",
    "mpl.rcParams[\"savefig.directory\"] = savedirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "kernelname = \"gemm_cltune_opencl\"\n",
    "\n",
    "algorithm_displaynames = {\n",
    "    'brute': \"bruteforce\",\n",
    "    'random': \"random\",\n",
    "}\n",
    "\n",
    "plot_height = 6\n",
    "plot_aspect = 2.0\n",
    "plot_dpi = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe() -> pd.DataFrame:\n",
    "\n",
    "    # collect the relevant cachefiles\n",
    "    cachefiles : list[Path] = []\n",
    "    for file in cachedirectory.iterdir():\n",
    "        if file.is_file() and file.name.startswith(kernelname) and file.suffix.endswith('_output.json'):\n",
    "            cachefiles.append(file)\n",
    "\n",
    "    # create a list of dictionaries of the data\n",
    "    cache_dicts = list()\n",
    "    for filepath in cachefiles:\n",
    "        # load the data\n",
    "        envfilepath = Path(str(filepath).replace('_output', '_env'))\n",
    "        assert envfilepath.exists()\n",
    "        try:\n",
    "            cachefile = json.load(filepath.open())\n",
    "            envfile = json.load(envfilepath)\n",
    "        except json.JSONDecodeError:\n",
    "            warn(f\"Could not load cachefile {filepath.name}\")\n",
    "            continue\n",
    "        assert isinstance(cachefile, dict)\n",
    "        assert isinstance(envfile, dict)\n",
    "\n",
    "        # combine the data into a dictionary\n",
    "        device_name = cachefile['device_name']\n",
    "        is_simulated = \"_mode=simulated\" in filepath.name\n",
    "        algorithm = algorithm_displaynames[re.search(r\"_alg-([a-zA-Z]+)_\", filepath.name).group(1).strip()]\n",
    "        # for each of the configurations, create a dictionary with the expected items\n",
    "        for value in cachefile['cache'].values():\n",
    "            assert isinstance(value, dict)\n",
    "            cache = {}\n",
    "            cache['device_name'] = device_name\n",
    "            cache['backend'] = backend\n",
    "            cache['backend | CUDA version'] = backend_CUDA\n",
    "            cache['CUDA version | backend'] = CUDA_backend\n",
    "            cache['CUDA version'] = CUDA_version\n",
    "            for key in expected_keys:\n",
    "                cache[key] = value[key]\n",
    "            cache['total_time'] = value['compile_time'] + value['benchmark_time'] + value['framework_time']\n",
    "            if observers:\n",
    "                for key in observer_keys:\n",
    "                    if key in value:\n",
    "                        cache[key] = value[key]\n",
    "            cache_dicts.append(cache)\n",
    "\n",
    "    # create a dataframe out of the dictionaries\n",
    "    df_ = pd.DataFrame(cache_dicts)\n",
    "    return df_.sort_values(['CUDA version', 'backend'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

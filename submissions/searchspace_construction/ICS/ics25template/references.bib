
@misc{TOP500November2024,
	title = {{TOP500} {November} 2024},
	url = {https://top500.org/lists/top500/2024/11/},
	urldate = {2025-02-21},
	journal = {TOP500},
	author = {{Hans Meuer} and {Erich Strohmaier} and {Jack Dongarra} and {Horst Simon} and {Martin Meuer}},
	month = nov,
	year = {2024},
}

@misc{comparingSixLanguages,
	title = {Comparative studies of six programming languages},
	author = {Alomari, Zakaria and Halimi, Oualid El and Sivaprasad, Kaushik and Pandit, Chitrang},
	year = {2015},
}

@misc{pythonVSC,
	title = {Comparative analysis of {C}++ and python in terms of memory and time},
	author = {Zehra, Farzeen and Javed, Maha and Khan, Darakhshan and Pasha, Maria},
	year = {2020},
	note = {Publisher: Preprints},
}

@inproceedings{pythonVSC++usability,
	title = {C++ or python? {Which} one to begin with: a learner's perspective},
	doi = {10.1109/LaTiCE.2014.20},
	booktitle = {2014 international conference on teaching and learning in computing and engineering},
	publisher = {IEEEXplore},
	author = {Ateeq, Muhammad and Habib, Hina and Umer, Adnan and Rehman, Muzammil Ul},
	year = {2014},
	keywords = {C++, Computer languages, Educational institutions, Introductory Programming, Learner, Problem-solving, Programming profession, Python, Syntactics},
	pages = {64--69},
}

@inproceedings{willemsenBayesianOptimizationAutotuning2021,
	title = {Bayesian {Optimization} for auto-tuning {GPU} kernels},
	doi = {10.1109/PMBS54543.2021.00017},
	abstract = {Finding optimal parameter configurations for tunable GPU kernels is a non-trivial exercise for large search spaces, even when automated. This poses an optimization task on a nonconvex search space, using an expensive to evaluate function with unknown derivative. These characteristics make a good candidate for Bayesian Optimization, which has not been applied to this problem before. However, the application of Bayesian Optimization to this problem is challenging. We demonstrate how to deal with the rough, discrete, constrained search spaces, containing invalid configurations. We introduce a novel contextual variance exploration factor, as well as new acquisition functions with improved scalability, combined with an informed acquisition function selection mechanism. By comparing the performance of our Bayesian Optimization implementation on various test cases to the existing search strategies in Kernel Tuner, as well as other Bayesian Optimization implementations, we demonstrate that our search strategies generalize well and consistently outperform other search strategies by a wide margin.},
	booktitle = {2021 {International} {Workshop} on {Performance} {Modeling}, {Benchmarking} and {Simulation} of {High} {Performance} {Computer} {Systems} ({PMBS})},
	publisher = {IEEE},
	author = {Willemsen, Floris-Jan and van Nieuwpoort, Rob and van Werkhoven, Ben},
	month = nov,
	year = {2021},
	keywords = {Bayes methods, Bayesian Optimization, Computational modeling, Convolution, GPU Computing, Graphics processing units, Optimization, Scalability, Search problems, Tuners, auto-tuning, machine learning},
	pages = {106--117},
}

@misc{schnellPycosatBindingsPicosat,
	title = {pycosat: bindings to picosat (a {SAT} solver)},
	copyright = {MIT},
	shorttitle = {pycosat},
	url = {https://github.com/ContinuumIO/pycosat},
	urldate = {2023-08-22},
	author = {Schnell, Ilan},
	month = mar,
	year = {2013},
	keywords = {Utilities},
}

@inproceedings{nardiHyperMapperPracticalDesign2019,
	title = {{HyperMapper}: a {Practical} {Design} {Space} {Exploration} {Framework}},
	shorttitle = {{HyperMapper}},
	url = {https://ieeexplore.ieee.org/document/9124618},
	doi = {10.1109/MASCOTS.2019.00053},
	abstract = {Design problems are ubiquitous in scientific and industrial achievements. Scientists design experiments to gain insights into physical and social phenomena, and engineers design machines to execute tasks more efficiently. These design problems are fraught with choices which are often complex and highdimensional and which include interactions that make them difficult for individuals to reason about. In software/hardware co-design, for example, companies develop libraries with tens or hundreds of free choices and parameters that interact in complex ways. In fact, the level of complexity is often so high that it becomes impossible to find domain experts capable of tuning these libraries [1].},
	urldate = {2024-05-23},
	booktitle = {2019 {IEEE} 27th {International} {Symposium} on {Modeling}, {Analysis}, and {Simulation} of {Computer} and {Telecommunication} {Systems} ({MASCOTS})},
	publisher = {IEEE},
	author = {Nardi, Luigi and Souza, Artur and Koeplinger, David and Olukotun, Kunle},
	month = oct,
	year = {2019},
	note = {ISSN: 2375-0227},
	keywords = {Computational modeling, Field programmable gate arrays, Optimization, Response surface methodology, Software, Space exploration, Tuning},
	pages = {425--426},
}

@misc{laszloSatispyInterfaceSAT,
	title = {satispy: {An} interface to {SAT} solver tools (like minisat)},
	copyright = {BSD License},
	shorttitle = {satispy},
	url = {https://github.com/netom/satispy/},
	urldate = {2023-08-22},
	author = {László, Fábián Tamás},
	month = feb,
	year = {2013},
	keywords = {Scientific/Engineering - Mathematics, Software Development - Libraries},
}

@misc{llcOrtoolsGoogleORTools,
	title = {ortools: {Google} {OR}-{Tools} python libraries and modules},
	copyright = {Apache Software License},
	shorttitle = {ortools},
	url = {https://developers.google.com/optimization/},
	urldate = {2023-08-22},
	author = {LLC, Google},
	month = sep,
	year = {2015},
	keywords = {Office/Business - Scheduling, Scientific/Engineering, Scientific/Engineering - Mathematics, Software Development, Software Development - Libraries - Python Modules, constraint programming,, flow algorithms,, linear programming,, operations research,, python},
}

@inproceedings{gunsCPMPy,
	title = {Increasing modeling language convenience with a universal n-dimensional array, {CPpy} as python-embedded example},
	volume = {19},
	url = {https://github.com/CPMpy/cpmpy},
	booktitle = {Proceedings of the 18th workshop on {Constraint} {Modelling} and {Reformulation} at {CP} ({Modref} 2019)},
	publisher = {Modref 2019},
	author = {Guns, Tias},
	year = {2019},
}

@misc{maniCSPSolverLibrarySolve,
	title = {{CSP}-{Solver}: {Library} to solve {Constraint} satisfation problems},
	copyright = {MIT License},
	shorttitle = {{CSP}-{Solver}},
	url = {https://github.com/LezendarySandwich/Generic-CSP-Solver},
	urldate = {2023-08-22},
	author = {Mani, Sanskar},
	month = sep,
	year = {2020},
}

@misc{niemeyerPythonconstraintPythonconstraintModule,
	title = {python-constraint: python-constraint is a module implementing support for handling {CSPs} ({Constraint} {Solving} {Problems}) over finite domain},
	copyright = {BSD License},
	shorttitle = {python-constraint},
	url = {https://github.com/python-constraint/python-constraint},
	urldate = {2023-08-22},
	author = {Niemeyer, Gustavo},
	month = jul,
	year = {2005},
	keywords = {Scientific/Engineering, constraint,, csp,, problem,, problems,, solver, solving,},
}

@inproceedings{BaCO2024,
	address = {New York, NY, USA},
	series = {Asplos '23},
	title = {{BaCO}: a fast and portable bayesian compiler optimization framework},
	isbn = {979-8-4007-0394-2},
	url = {https://doi.org/10.1145/3623278.3624770},
	doi = {10.1145/3623278.3624770},
	abstract = {We introduce the Bayesian Compiler Optimization framework (BaCO), a general purpose autotuner for modern compilers targeting CPUs, GPUs, and FPGAs. BaCO provides the flexibility needed to handle the requirements of modern autotuning tasks. Particularly, it deals with permutation, ordered, and continuous parameter types along with both known and unknown parameter constraints. To reason about these parameter types and efficiently deliver high-quality code, BaCO uses Bayesian optimization algorithms specialized towards the autotuning domain. We demonstrate BaCO's effectiveness on three modern compiler systems: TACO, RISE \& ELEVATE, and HPVM2FPGA for CPUs, GPUs, and FPGAs respectively. For these domains, BaCO outperforms current state-of-the-art auto-tuners by delivering on average 1.36X–1.56X faster code with a tiny search budget, and BaCO is able to reach expert-level performance 2.9X–3.9X faster.},
	booktitle = {Proceedings of the 28th {ACM} international conference on architectural support for programming languages and operating systems, volume 4},
	publisher = {Association for Computing Machinery},
	author = {Hellsten, Erik Orm and Souza, Artur and Lenfers, Johannes and Lacouture, Rubens and Hsu, Olivia and Ejjeh, Adel and Kjolstad, Fredrik and Steuwer, Michel and Olukotun, Kunle and Nardi, Luigi},
	month = feb,
	year = {2024},
	note = {Number of pages: 24
Place: Vancouver, BC, Canada},
	keywords = {autoscheduling, autotuning, bayesian optimization, compiler optimizations, high-performance computing},
	pages = {19--42},
}

@inproceedings{KTT,
	address = {New York, NY, USA},
	series = {Andare '17},
	title = {Autotuning of {OpenCL} kernels with global optimizations},
	isbn = {978-1-4503-5363-2},
	url = {https://doi.org/10.1145/3152821.3152877},
	doi = {10.1145/3152821.3152877},
	abstract = {Autotuning is an important method for automatically exploring code optimizations. It may target low-level code optimizations, such as memory blocking, loop unrolling or memory prefetching, as well as high-level optimizations, such as placement of computation kernels on proper hardware devices, optimizing memory transfers between nodes or between accelerators and main memory.In this paper, we introduce an autotuning method, which extends state-of-the-art low-level tuning of OpenCL or CUDA kernels towards more complex optimizations. More precisely, we introduce a Kernel Tuning Toolkit (KTT), which implements inter-kernel global optimizations, allowing to tune parameters affecting multiple kernels or also the host code. We demonstrate on practical examples, that with global kernel optimizations we are able to explore tuning options that are not possible if kernels are tuned separately. Moreover, our tuning strategies can take into account numerical accuracy across multiple kernel invocations and search for implementations within specific numerical error bounds.},
	booktitle = {Proceedings of the 1st workshop on {AutotuniNg} and adaptivity {AppRoaches} for energy efficient {HPC} systems},
	publisher = {Association for Computing Machinery},
	author = {Filipovič, Jiři and Petrovič, Filip and Benkner, Siegfried},
	month = sep,
	year = {2017},
	note = {Number of pages: 6
Place: Portland, OR, USA
tex.articleno: 2},
}

@inproceedings{AUMA,
	address = {Hyderabad, India},
	title = {Machine learning based auto-tuning for enhanced {OpenCL} performance portability},
	doi = {10.1109/IPDPSW.2015.85},
	booktitle = {2015 {IEEE} international parallel and distributed processing symposium workshop},
	publisher = {IEEE},
	author = {Falch, T. L. and Elster, A. C.},
	month = may,
	year = {2015},
	pages = {1231--1240},
}

@article{smtcomp2007,
	title = {Design and results of the 3rd annual satisfiability modulo theories competition ({SMT}-{COMP} 2007)},
	volume = {17},
	number = {04},
	journal = {International Journal on Artificial Intelligence Tools},
	author = {Barrett, Clark and Deters, Morgan and Oliveras, Albert and Stump, Aaron},
	year = {2008},
	note = {Publisher: World Scientific},
	pages = {569--606},
}

@inproceedings{Z3solver,
	title = {Z3: {An} efficient {SMT} solver},
	booktitle = {International conference on tools and algorithms for the construction and analysis of systems},
	publisher = {Springer},
	author = {De Moura, Leonardo and Bjørner, Nikolaj},
	year = {2008},
	pages = {337--340},
}

@article{heydarian2018template,
	title = {Template-free {2D} particle fusion in localization microscopy},
	volume = {15},
	number = {10},
	journal = {Nature methods},
	author = {Heydarian, Hamidreza and Schueder, Florian and Strauss, Maximilian T and van Werkhoven, Ben and Fazel, Mohamadreza and Lidke, Keith A and Jungmann, Ralf and Stallinga, Sjoerd and Rieger, Bernd},
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	pages = {781--784},
}

@inproceedings{pruning,
	address = {New York, NY, USA},
	series = {Cgo '08},
	title = {Program optimization space pruning for a multithreaded gpu},
	isbn = {978-1-59593-978-4},
	url = {https://doi.org/10.1145/1356058.1356084},
	doi = {10.1145/1356058.1356084},
	abstract = {Program optimization for highly-parallel systems has historically been considered an art, with experts doing much of the performance tuning by hand. With the introduction of inexpensive, single-chip, massively parallel platforms, more developers will be creating highly-parallel applications for these platforms, who lack the substantial experience and knowledge needed to maximize their performance. This creates a need for more structured optimization methods with means to estimate their performance effects. Furthermore these methods need to be understandable by most programmers. This paper shows the complexity involved in optimizing applications for one such system and one relatively simple methodology for reducing the workload involved in the optimization process.This work is based on one such highly-parallel system, the GeForce 8800 GTX using CUDA. Its flexible allocation of resources to threads allows it to extract performance from a range of applications with varying resource requirements, but places new demands on developers who seek to maximize an application's performance. We show how optimizations interact with the architecture in complex ways, initially prompting an inspection of the entire configuration space to find the optimal configuration. Even for a seemingly simple application such as matrix multiplication, the optimal configuration can be unexpected. We then present metrics derived from static code that capture the first-order factors of performance. We demonstrate how these metrics can be used to prune many optimization configurations, down to those that lie on a Pareto-optimal curve. This reduces the optimization space by as much as 98\% and still finds the optimal configuration for each of the studied applications.},
	booktitle = {Proceedings of the 6th annual {IEEE}/{ACM} international symposium on code generation and optimization},
	publisher = {Association for Computing Machinery},
	author = {Ryoo, Shane and Rodrigues, Christopher I. and Stone, Sam S. and Baghsorkhi, Sara S. and Ueng, Sain-Zee and Stratton, John A. and Hwu, Wen-mei W.},
	year = {2008},
	note = {Number of pages: 10
Place: Boston, MA, USA},
	keywords = {gpgpu, optimization, parallel computing},
	pages = {195--204},
}

@inproceedings{li2009note,
	title = {A note on auto-tuning {GEMM} for {GPUs}},
	booktitle = {Computational science–{ICCS} 2009: 9th international conference baton rouge, la, {USA}, may 25-27, 2009 proceedings, part {I} 9},
	publisher = {Springer},
	author = {Li, Yinan and Dongarra, Jack and Tomov, Stanimire},
	year = {2009},
	pages = {884--892},
}

@misc{khudiaFBGEMMEnablingHighperformance2021,
	title = {{FBGEMM}: {Enabling} high-performance low-precision deep learning inference},
	abstract = {Deep learning models typically use single-precision (FP32) floating point data types for representing activations and weights, but a slew of recent research work has shown that computations with reduced-precision data types (FP16, 16-bit integers, 8-bit integers or even 4- or 2-bit integers) are enough to achieve same accuracy as FP32 and are much more efficient. Therefore, we designed fbgemm, a high-performance kernel library, from ground up to perform high-performance quantized inference on current generation CPUs. fbgemm achieves efficiency by fusing common quantization opera- tions with a high-performance gemm implementation and by shape- and size-specific kernel code generation at runtime. The library has been deployed at Facebook, where it delivers greater than 2× performance gains with respect to our current production baseline.},
	language = {English},
	urldate = {2024-03-11},
	author = {Khudia, Daya and Huang, Jianyu and Basu, Protonu and Deng, Summer and Liu, Haixin and Park, Jongsoo and Smelyanskiy, Mikhail},
	year = {2021},
}

@misc{heldensKernelLauncherLibrary2023,
	title = {Kernel {Launcher}: {C}++ {Library} for {Optimal}-{Performance} {Portable} {CUDA} {Applications}},
	shorttitle = {Kernel {Launcher}},
	url = {http://arxiv.org/abs/2303.12374},
	doi = {10.48550/arXiv.2303.12374},
	abstract = {Graphic Processing Units (GPUs) have become ubiquitous in scientific computing. However, writing efficient GPU kernels can be challenging due to the need for careful code tuning. To automatically explore the kernel optimization space, several auto-tuning tools - like Kernel Tuner - have been proposed. Unfortunately, these existing auto-tuning tools often do not concern themselves with integration of tuning results back into applications, which puts a significant implementation and maintenance burden on application developers. In this work, we present Kernel Launcher: an easy-to-use C++ library that simplifies the creation of highly-tuned CUDA applications. With Kernel Launcher, programmers can capture kernel launches, tune the captured kernels for different setups, and integrate the tuning results back into applications using runtime compilation. To showcase the applicability of Kernel Launcher, we consider a real-world computational fluid dynamics code and tune its kernels for different GPUs, input domains, and precisions.},
	urldate = {2023-12-20},
	publisher = {arXiv},
	author = {Heldens, Stijn and van Werkhoven, Ben},
	month = mar,
	year = {2023},
	note = {arXiv:2303.12374 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
}

@article{pop00057,
	title = {{M2C}: a massive performance and energy throttling framework for high-performance computing systems},
	url = {https://www.researchgate.net/profile/Amna_Arshad12/publication/343421445_M2C_A_Massive_Performance_and_Energy_Throttling_Framework_for_High-Performance_Computing_Systems/links/5f2db77392851cd302e751d8/M2C-A-Massive-Performance-and-Energy-Throttling-Framework-for-High-Performance-Computing-Systems.pdf},
	abstract = {… C. M2C Framework We have shown the architecture of our proposed model M2C (see Fig … GHz processing power, which is what is operated by Cent Operating System-v6.4. CUDA toolkit version-9.1 … GDR 2.3.1 is used to enable MPI with the support of accelerated GPU devices …},
	journal = {researchgate.net},
	author = {Ashraf, MU and Jambi, KM and Arshad, A and Aslam, R and Ilyas, I},
	note = {Type: PDF},
}

@article{pop00013,
	title = {Framework for parallel kernels auto-tuning},
	url = {https://is.muni.cz/th/a7xtl/Thesis.pdf},
	abstract = {… The following two chapters are dedicated to KTT (Kernel Tuning Toolkit) framework, which was developed in this thesis … Tuner 12 Page 20. 3. Code variant auto-tuning and related frameworks … 3.3 CLTune CLTune [1] is a framework for auto-tuning of OpenCL and CUDA kernels …},
	journal = {is.muni.cz},
	author = {Petrovič, BF},
	note = {Type: PDF},
}

@article{pop00026,
	title = {D5. 5–{BOAST}: a metaprogramming framework to produce portable and efficient computing kernels for {HPC} applications version 1.0},
	url = {https://www.montblanc-project.eu/wp-content/uploads/2017/12/D5.5_0.pdf},
	abstract = {… Debugging applications running on GPU environments is well-recognized as a hard and time- consuming activity … The tool relies on BOAST support of multi-target code … D5.5 - BOAST: a Metaprogramming Framework to Produce Portable and Efficient Computing Kernels for HPC …},
	journal = {montblanc-project.eu},
	author = {UJF, FBT and CEA, TD and CEA, LG and UJF, JFM and Pouget, K and {...}},
	note = {Type: PDF},
}

@article{brailsfordConstraintSatisfactionProblems1999,
	title = {Constraint satisfaction problems: {Algorithms} and applications},
	volume = {119},
	issn = {0377-2217},
	shorttitle = {Constraint satisfaction problems},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221798003646},
	doi = {10.1016/S0377-2217(98)00364-6},
	abstract = {A constraint satisfaction problem (CSP) requires a value, selected from a given finite domain, to be assigned to each variable in the problem, so that all constraints relating the variables are satisfied. Many combinatorial problems in operational research, such as scheduling and timetabling, can be formulated as CSPs. Researchers in artificial intelligence (AI) usually adopt a constraint satisfaction approach as their preferred method when tackling such problems. However, constraint satisfaction approaches are not widely known amongst operational researchers. The aim of this paper is to introduce constraint satisfaction to the operational researcher. We start by defining CSPs, and describing the basic techniques for solving them. We then show how various combinatorial optimization problems are solved using a constraint satisfaction approach. Based on computational experience in the literature, constraint satisfaction approaches are compared with well-known operational research (OR) techniques such as integer programming, branch and bound, and simulated annealing.},
	number = {3},
	urldate = {2023-08-22},
	journal = {European Journal of Operational Research},
	author = {Brailsford, Sally C. and Potts, Chris N. and Smith, Barbara M.},
	month = dec,
	year = {1999},
	keywords = {Combinatorial optimization, Constraint satisfaction, Integer programming, Local search},
	pages = {557--581},
}

@inproceedings{ActiveHarmony,
	series = {Proceedings from the {Conference} on {High} {Performance} {Networking} and {Computing}},
	title = {Active harmony: {Towards} automated performance tuning},
	isbn = {0-7695-1524-X},
	doi = {10.1109/SC.2002.10062},
	booktitle = {Proceedings from the conference on high performance networking and computing},
	author = {Tapus, Cristian and Chung, I-Hsin and Hollingsworth, J.K.},
	month = dec,
	year = {2002},
	pages = {44 -- 44},
}

@misc{OpenCL,
	title = {The khronos group releases {OpenCL} 1.0 specification},
	url = {https://web.archive.org/web/20100713014204/http://www.khronos.org/news/press/releases/the_khronos_group_releases_opencl_1.0_specification/},
	author = {Riegel, Elizabeth},
	year = {2008},
}

@inproceedings{fftw1998,
	title = {{FFTW}: {An} adaptive software architecture for the {FFT}},
	volume = {3},
	booktitle = {Acoustics, speech and signal processing, 1998. {Proceedings} of the 1998 {IEEE} international conference on},
	publisher = {IEEE},
	author = {Frigo, Matteo and Johnson, Steven G},
	year = {1998},
	pages = {1381--1384},
}

@article{atlas2001,
	title = {Automated empirical optimizations of software and the {ATLAS} project},
	volume = {27},
	number = {1-2},
	journal = {Parallel Computing},
	author = {Whaley, R Clint and Petitet, Antoine and Dongarra, Jack J},
	year = {2001},
	note = {Publisher: Elsevier},
	pages = {3--35},
}

@misc{CUDA,
	title = {{NVIDIA} {CUDA} compute unified device architecture programming guide},
	url = {http://developer.download.nvidia.com/compute/cuda/1.0/NVIDIA_CUDA_Programming_Guide_1.0.pdf},
	author = {Corporation, NVIDIA},
	year = {2007},
}

@incollection{barrett2008satisfiability,
	series = {Frontiers in {Artificial} {Intelligence} and {Applications}},
	title = {Satisfiability {Modulo} {Theories}. {Frontiers} in artificial intelligence and applications, vol. 185, ch. 26},
	volume = {185},
	isbn = {978-1-58603-929-5},
	shorttitle = {Satisfiability {Modulo} {Theories}},
	language = {English},
	booktitle = {Handbook of {Satisfiability}},
	publisher = {IOS Press},
	author = {Barrett, Clark and Sebastiani, Roberto and Seshia, Sanjit and Tinelli, Cesare},
	year = {2008},
	pages = {825--885},
}

@inproceedings{Orio,
	address = {Rome, Italy,},
	title = {Annotation-based empirical performance tuning using {Orio}},
	doi = {10.1109/IPDPS.2009.5161004},
	booktitle = {2009 {IEEE} international symposium on parallel distributed processing},
	publisher = {IEEE},
	author = {Hartono, A. and Norris, B. and Sadayappan, P.},
	year = {2009},
	pages = {1--11},
}

@book{biereHandbookSatisfiabilityVolume2009,
	address = {NLD},
	title = {Handbook of {Satisfiability}: {Volume} 185 {Frontiers} in {Artificial} {Intelligence} and {Applications}},
	isbn = {978-1-58603-929-5},
	shorttitle = {Handbook of {Satisfiability}},
	abstract = {'Satisfiability (SAT) related topics have attracted researchers from various disciplines: logic, applied areas such as planning, scheduling, operations research and combinatorial optimization, but also theoretical issues on the theme of complexity and much more, they all are connected through SAT. My personal interest in SAT stems from actual solving: The increase in power of modern SAT solvers over the past 15 years has been phenomenal. It has become the key enabling technology in automated verification of both computer hardware and software. Bounded Model Checking (BMC) of computer hardware is now probably the most widely used model checking technique. The counterexamples that it finds are just satisfying instances of a Boolean formula obtained by unwinding to some fixed depth a sequential circuit and its specification in linear temporal logic. Extending model checking to software verification is a much more difficult problem on the frontier of current research. One promising approach for languages like C with finite word-length integers is to use the same idea as in BMC but with a decision procedure for the theory of bit-vectors instead of SAT. All decision procedures for bit-vectors that I am familiar with ultimately make use of a fast SAT solver to handle complex formulas. Decision procedures for more complicated theories, like linear real and integer arithmetic, are also used in program verification. Most of them use powerful SAT solvers in an essential way. Clearly, efficient SAT solving is a key technology for 21st century computer science. I expect this collection of papers on all theoretical and practical aspects of SAT solving will be extremely useful to both students and researchers and will lead to many further advances in the field.' Edmund Clarke (FORE Systems University Professor of Computer Science and Professor of Electrical and Computer Engineering at Carnegie Mellon University)},
	publisher = {IOS Press},
	author = {Biere, A. and Biere, A. and Heule, M. and van Maaren, H. and Walsh, T.},
	month = jan,
	year = {2009},
}

@misc{CUDAFermi,
	title = {Next generation {CUDA} {TM} compute architecture fermi {V1}.1},
	url = {https://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf},
	author = {Corporation, NVIDIA},
	year = {2009},
}

@inproceedings{Liu,
	address = {Rome, Italy},
	title = {A cross-input adaptive framework for {GPU} program optimizations},
	doi = {10.1109/IPDPS.2009.5160988},
	booktitle = {2009 {IEEE} international symposium on parallel distributed processing},
	publisher = {IEEE},
	author = {Liu, Y. and Zhang, E. Z. and Shen, X.},
	year = {2009},
	pages = {1--10},
}

@inproceedings{FFT_CUDA,
	address = {Portland, OR, USA},
	title = {Auto-tuning 3-{D} {FFT} library for {CUDA} gpus},
	doi = {10.1145/1654059.1654090},
	booktitle = {Proceedings of the conference on high performance computing networking, storage and analysis},
	publisher = {IEEE},
	author = {Nukada, A. and Matsuoka, S.},
	year = {2009},
	pages = {1--10},
}

@article{pop00036,
	title = {Towards a tunable multi-backend skeleton programming framework for multi-{GPU} systems},
	url = {http://www.par.univie.ac.at/project/peppher/publications/TunableSkePU-MCC2010.pdf},
	abstract = {… and also different variations of the same skeleton (eg different user functions) requires flexibility in the tuning framework … We consider two different GPU-based target architectures … Intel(R) Xeon (R) E5520 server clocked at 2.27 GHz with 2 NVIDIA GT200 (Tesla C1060) GPUs …},
	journal = {Proceedings of the rd …},
	author = {Enmyren, J and Dastgeer, U and Kessler, CW},
	year = {2010},
	note = {Publisher: par.univie.ac.at
Type: PDF},
}

@inproceedings{Maestro,
	address = {Berlin, Heidelberg},
	title = {Maestro: {Data} orchestration and tuning for {OpenCL} devices},
	isbn = {978-3-642-15291-7},
	booktitle = {Euro-par 2010 - parallel processing},
	publisher = {Springer Berlin Heidelberg},
	author = {Spafford, Kyle and Meredith, Jeremy and Vetter, Jeffrey},
	editor = {D'Ambra, Pasqua and Guarracino, Mario and Talia, Domenico},
	year = {2010},
	pages = {275--286},
}

@article{pop00055,
	title = {Fast wavelet transform utilizing a multicore-aware framework},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-28145-7_31},
	abstract = {… It is not a black box that tries to create fast code, but a tool that lets the … Procedia Computer Science 1(1), 1095–1104 (2010) 7. Garcia, A., Shen, H.: GPU-based 3D wavelet … Stürmer, M., Rüde, U.: A framework that supports in writing performance- optimized stencil-based codes …},
	journal = {International Workshop on Applied Parallel …},
	author = {Stürmer, M and Köstler, H and Rüde, U},
	year = {2010},
	note = {Publisher: Springer},
}

@article{pop00046,
	title = {A massive data parallel computational framework for petascale/exascale hybrid computer systems},
	url = {https://arxiv.org/abs/1201.2118},
	abstract = {… The Cactus Computational Toolkit (CCTK) is a collection of thorns which pro- vide basic … In this work the Cactus framework has been extended to cover GPU execution via an … The Cactus Framework already has a mechanism, implemented through the configuration.ccl file, by …},
	journal = {arXiv preprint arXiv …},
	author = {Blazewicz, M and Brandt, SR and Diener, P and {...}},
	year = {2012},
	note = {Publisher: arxiv.org},
}

@article{behnelCythonBestBoth2011,
	title = {Cython: {The} {Best} of {Both} {Worlds}},
	volume = {13},
	issn = {1558-366X},
	shorttitle = {Cython},
	url = {https://ieeexplore.ieee.org/abstract/document/5582062?casa_token=vX01EeD4jIgAAAAA:iH9MrU9z476s5URxaiakD6e4tk7TUKXFpEs3gwrF0QeechZzJcb7w0czrkaMI2MB0LIyXGqbcQ},
	doi = {10.1109/MCSE.2010.118},
	abstract = {Cython is a Python language extension that allows explicit type declarations and is compiled directly to C. As such, it addresses Python's large overhead for numerical loops and the difficulty of efficiently using existing C and Fortran code, which Cython can interact with natively.},
	number = {2},
	urldate = {2024-03-12},
	journal = {Computing in Science \& Engineering},
	author = {Behnel, Stefan and Bradshaw, Robert and Citro, Craig and Dalcin, Lisandro and Seljebotn, Dag Sverre and Smith, Kurt},
	month = mar,
	year = {2011},
	note = {Conference Name: Computing in Science \& Engineering},
	keywords = {Computer programs, Cython, Programming, Python, Runtime, Sparse matrices, Syntactics, numerics, scientific computing},
	pages = {31--39},
}

@article{pop00074,
	title = {Auto-tuning {SkePU}: a multi-backend skeleton programming framework for multi-{GPU} systems},
	url = {https://dl.acm.org/doi/abs/10.1145/1984693.1984697},
	abstract = {… [1] J. Breitbart. CuPP - A framework for easy CUDA integration … IEEE Computer Society. [2] Sara S. Baghsorkhi, Matthieu Delahaye, Sanjay J. Patel, William D. Gropp, and Wen-mei W. Hwu, An adaptive performance modeling tool for GPU architectures Proc …},
	journal = {Proceedings of the 4th …},
	author = {Dastgeer, U and Enmyren, J and Kessler, CW},
	year = {2011},
	note = {Publisher: dl.acm.org},
}

@article{bofillSolvingConstraintSatisfaction2012,
	title = {Solving constraint satisfaction problems with {SAT} modulo theories},
	volume = {17},
	issn = {1572-9354},
	url = {https://doi.org/10.1007/s10601-012-9123-1},
	doi = {10.1007/s10601-012-9123-1},
	abstract = {Due to significant advances in SAT technology in the last years, its use for solving constraint satisfaction problems has been gaining wide acceptance. Solvers for satisfiability modulo theories (SMT) generalize SAT solving by adding the ability to handle arithmetic and other theories. Although there are results pointing out the adequacy of SMT solvers for solving CSPs, there are no available tools to extensively explore such adequacy. For this reason, in this paper we introduce a tool for translating FLATZINC (MINIZINC intermediate code) instances of CSPs to the standard SMT-LIB language. We provide extensive performance comparisons between state-of-the-art SMT solvers and most of the available FLATZINC solvers on standard FLATZINC problems. The obtained results suggest that state-of-the-art SMT solvers can be effectively used to solve CSPs.},
	language = {en},
	number = {3},
	urldate = {2023-08-22},
	journal = {Constraints},
	author = {Bofill, Miquel and Palahí, Miquel and Suy, Josep and Villaret, Mateu},
	month = jul,
	year = {2012},
	keywords = {Constraint programming, Reformulation, Satisfiability modulo theories, Solvers and tools},
	pages = {273--303},
}

@inproceedings{ASK,
	address = {Berlin, Heidelberg},
	title = {{ASK}: {Adaptive} sampling kit for performance characterization},
	isbn = {978-3-642-32820-6},
	abstract = {Characterizing performance is essential to optimize programs and architectures. The open source Adaptive Sampling Kit (ASK) measures the performance trade-offs in large design spaces. Exhaustively sampling all points is computationally intractable. Therefore, ASK concentrates exploration in the most irregular regions of the design space through multiple adaptive sampling methods. The paper presents the ASK architecture and a set of adaptive sampling strategies, including a new approach: Hierarchical Variance Sampling. ASK's usage is demonstrated on two performance characterization problems: memory stride accesses and stencil codes. ASK builds precise models of performance with a small number of measures. It considerably reduces the cost of performance exploration. For instance, the stencil code design space, which has more than 31.108 points, is accurately predicted using only 1 500 points.},
	booktitle = {Euro-par 2012 parallel processing},
	publisher = {Springer Berlin Heidelberg},
	author = {de Oliveira Castro, Pablo and Petit, Eric and Beyler, Jean Christophe and Jalby, William},
	editor = {Kaklamanis, Christos and Papatheodorou, Theodore and Spirakis, Paul G.},
	year = {2012},
	pages = {89--101},
}

@book{pop00063,
	title = {A compiler toolkit for array-based languages targeting {CPU}/{GPU} hybrid systems},
	url = {http://www.sable.mcgill.ca/publications/techreports/2012-3/sable-tr-2012-3.pdf},
	abstract = {… In order to provide a general-purpose tool which could be retargeted for a variety of CPU … Thus, RaijinCL serves well as a key component of our toolkit, and can be used both with … aid in the design of Velociraptor, and to demonstrate two different uses of the framework, we used …},
	publisher = {sable.mcgill.ca},
	author = {Garg, R and Hendren, L},
	year = {2012},
	note = {Type: PDF},
}

@article{kloecknerPyCUDA2012,
	title = {{PyCUDA} and {PyOpenCL}: {A} scripting-based approach to {GPU} run-time code generation},
	volume = {38},
	issn = {0167-8191},
	doi = {10.1016/j.parco.2011.09.001},
	number = {3},
	journal = {Parallel Computing},
	author = {Klöckner, Andreas and Pinto, Nicolas and Lee, Yunsup and Catanzaro, B. and Ivanov, Paul and Fasih, Ahmed},
	year = {2012},
	pages = {157--174},
}

@article{pop00033,
	title = {Op2: {An} active library framework for solving unstructured mesh-based applications on multi-core and many-core architectures},
	url = {https://ieeexplore.ieee.org/abstract/document/6339594/},
	abstract = {… Gauss-Seidel or ILU (incomplete LU decomposition), lie beyond the current ca pabilities ofthe framework … Thus on a GPU the execution of a given loop makes optimum use of the … Until recently, NVIDIA GPUs did not have caches and most applications have used structured grids …},
	journal = {2012 Innovative …},
	author = {Mudalige, GR and Giles, MB and Reguly, I and {...}},
	year = {2012},
	note = {Publisher: ieeexplore.ieee.org},
}

@article{pop00025,
	title = {A scalable framework for heterogeneous {GPU}-based clusters},
	url = {https://dl.acm.org/doi/abs/10.1145/2312005.2312025},
	abstract = {… 5. THE FRAMEWORK IMPLEMENTATION As shown in Fig … If there are a number of g GPUs, there will be 2g cudaMemcpyAsync operations happening concurrently in … can sim- ply look up the structure and pass correct arguments (ie GPU device pointers) to launch GPU kernels …},
	journal = {Proceedings of the twenty-fourth annual ACM …},
	author = {Song, F and Dongarra, J},
	year = {2012},
	note = {Publisher: dl.acm.org},
}

@book{pop00027,
	title = {Multi-{GPU} support on the marrow algorithmic skeleton framework},
	url = {https://run.unl.pt/handle/10362/10746},
	abstract = {… 51 4.12 Auto-tuner work-space partitioning and overlap partitions … Brook [BH03] was the first framework of its kind to be created in 2003, demonstrating the potential of GPGPU … Cg [Mar+03], a C-like pro- gramming language which compiles to OpenGL shaders for GPU execution …},
	publisher = {run.unl.pt},
	author = {Alexandre, FJM},
	year = {2013},
}

@article{Sesame,
	title = {Sesame: a user-transparent optimizing framework for many-core processors},
	url = {https://ieeexplore.ieee.org/abstract/document/6546061/},
	abstract = {… Using an auto-tuner, we find the optimal solution within this optimization space for a … Our Sesame framework is scalable and it can integrate more modules when new architectural features … Based on C, CUDA uses language extensions for separating device (ie, GPU) from host …},
	journal = {2013 13th IEEE/ACM …},
	author = {Fang, J and Varbanescu, AL and Sips, H},
	year = {2013},
	note = {Publisher: ieeexplore.ieee.org},
}

@book{CollectiveMind,
	address = {Taiwan},
	title = {Tutorial at {HPSC} 2013 at {NTU}, {Taiwan}: {Collective} {Mind}: novel methodology, framework and repository to crowd-source auto-tuning},
	url = {https://hal.inria.fr/hal-00819002/},
	abstract = {… Continue exploring design and optimization spaces (evaluate different architectures, optimizations, compilers, etc.) Focus exploration on unexplored … Page 22. Grigori Fursin “Collective Mind: novel methodology, framework and repository to crowdsource auto-tuning” …},
	publisher = {hal.inria.fr},
	author = {Fursin, G},
	year = {2013},
}

@book{pop00018,
	title = {A framework for productive, efficient and portable parallel computing},
	url = {https://escholarship.org/uc/item/7hs0x0mp},
	abstract = {… We aim to demonstrate the same application running on a multi- core CPU, a GPU and a computer cluster without significant application code change … We propose and develop a framework called PyCASP … allel hardware including multi-core CPUs, NVIDIA GPUs and clusters …},
	publisher = {escholarship.org},
	author = {Gonina, E},
	year = {2013},
}

@article{pop00068,
	title = {{PARTANS}: {An} autotuning framework for stencil computation on multi-{GPU} systems},
	url = {https://dl.acm.org/doi/abs/10.1145/2400682.2400718},
	abstract = {… Page 9. PARTANS: An Autotuning Framework for Stencil Computation on Multi-GPU Systems 59:9 … The tested graphics cards are two dual GPU cards … The Nvidia GTX 590 also has two GPUs based on the Fermi architecture and uses an Nvidia NF200 multiplexer …},
	journal = {… on Architecture and Code Optimization …},
	author = {Lutz, T and Fensch, C and Cole, M},
	year = {2013},
	note = {Publisher: dl.acm.org},
}

@article{pop00070,
	title = {Paraiso: an automated tuning framework for explicit solvers of partial differential equations},
	url = {https://iopscience.iop.org/article/10.1088/1749-4699/5/1/015003/meta},
	abstract = {… not just as a tool to avoid manual tuning, but as a necessary tool to have … Just for comparison, the Paraiso framework is about 5000 lines of code in Haskell, and the … 4], overlapping communication with computation [5, 12] or heterogeneous utilization of CPU/GPU (CPU = central …},
	journal = {Computational Science \& Discovery},
	author = {Muranushi, T},
	year = {2012},
	note = {Publisher: iopscience.iop.org},
}

@article{pop00024,
	title = {{PyOP2}: {A} high-level framework for performance-portable simulations on unstructured meshes},
	url = {https://ieeexplore.ieee.org/abstract/document/6495916/},
	abstract = {… Integrating this tool chain into a general purpose, multi- phase computational fluid dynamics code … FRAMEWORK PyOP2 is a Python implementation of the unstructured mesh computation framework OP2 [1 … For maximum occupancy on a NVIDIA Fermi GPU with up to 1.5K …},
	journal = {2012 SC Companion …},
	author = {Rathgeber, F and Markall, GR and Mitchell, L and {...}},
	year = {2012},
	note = {Publisher: ieeexplore.ieee.org},
}

@book{pop00040,
	title = {Elastic computing: a framework for effective multi-core heterogeneous computing},
	url = {http://search.proquest.com/openview/579123027f29da8471a9cb431864c138/1?pq-origsite=gscholar&cbl=18750&diss=y},
	abstract = {… like to use multi-core heterogeneous systems without becoming experts in FPGA's, GPU's, etc. [38] … the framework (eg, C/C++, assembly, FORTRAN). The implementation code can … the implementations must be thread-safe, as the function execution tool may spawn …},
	publisher = {search.proquest.com},
	author = {Wernsing, JR},
	year = {2012},
	note = {Type: BOOK},
}

@article{pop00045,
	title = {From physics model to results: {An} optimizing framework for cross-architecture code generation},
	url = {https://content.iospress.com/articles/scientific-programming/spr360},
	abstract = {… Kranc is not just a theoretical tool … All of the above features are used heavily by users of the Toolkit, and hence have been well-tested on many production architectures, including most systems at NERSC or in … From physics model to results: An optimizing framework for cross …},
	journal = {Scientific …},
	author = {Blazewicz, M and Hinder, I and Koppelman, DM and {...}},
	year = {2013},
	note = {Publisher: content.iospress.com},
}

@article{Halide,
	title = {Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines},
	volume = {48},
	issn = {0362-1340},
	url = {https://doi-org.vu-nl.idm.oclc.org/10.1145/2499370.2462176},
	doi = {10.1145/2499370.2462176},
	number = {6},
	journal = {SIGPLAN Not.},
	author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Frédo and Amarasinghe, Saman},
	month = jun,
	year = {2013},
	note = {Number of pages: 12
Place: New York, NY, USA
Publisher: Association for Computing Machinery
tex.issue\_date: June 2013},
	pages = {519--530},
}

@article{Nitro,
	title = {Nitro: {A} framework for adaptive code variant tuning},
	url = {https://ieeexplore.ieee.org/abstract/document/6877283/},
	abstract = {… To date, no general-purpose framework enables users to specify and tune arbitrary code … The tuner then runs automatically, checking the prediction performance at each step on the … we use 6 (linear solver, preconditioner) combinations from the CULA Sparse toolkit [26], which is …},
	journal = {2014 IEEE 28th …},
	author = {Muralidharan, S and Shantharam, M and Hall, M and {...}},
	year = {2014},
	note = {Publisher: ieeexplore.ieee.org},
}

@article{pop00010,
	title = {A stream processing framework for on-line optimization of performance and energy efficiency on heterogeneous systems},
	url = {https://ieeexplore.ieee.org/abstract/document/6969495/},
	abstract = {… optional functionality making it particularly efficient to use discrete-memory GPUs compatible with the CUDA framework … accessible GPU is copied to the host and from there to the target GPU. IV … Open source implementations for both CPUs and GPUs exist for the SURF [49] and …},
	journal = {2014 IEEE International …},
	author = {Ranft, B and Denninger, O and Pfaffe, P},
	year = {2014},
	note = {Publisher: ieeexplore.ieee.org},
}

@article{pop00021,
	title = {Chemora: a {PDE} solving framework for modern {HPC} architectures},
	url = {https://arxiv.org/abs/1410.1764},
	abstract = {… We consider the Einstein Toolkit to be a very success- ful endeavour, cited in probably more … However, we want to mention in par- ticular Modelica as a tool-indepent and discretization … type definitions, or compos- ing models; EDL regains some of these via the Cactus framework …},
	journal = {arXiv preprint arXiv …},
	author = {Schnetter, E and Blazewicz, M and Brandt, SR and {...}},
	year = {2014},
	note = {Publisher: arxiv.org},
}

@book{pop00050,
	title = {Seventh framework programme},
	url = {https://prace-ri.eu/wp-content/uploads/3IP-D7.2.1.pdf},
	abstract = {SEVENTH FRAMEWORK PROGRAMME … Survey of HPC Tools and Techniques ID: D7.2.1 Version: ¡1.0 ¿ Status: Final Available at: http://www.prace-project.eu Software Tool: Microsoft Word … 47 2.12 Global Arrays Toolkit …},
	publisher = {prace-ri.eu},
	author = {Lysaght, M and Lindi, IB and Vondrak, V and Donners, VSBJ and {...}},
	year = {2013},
	note = {Type: PDF},
}

@article{pop00034,
	title = {Design and initial performance of a high-level unstructured mesh framework on heterogeneous parallel systems},
	url = {https://www.sciencedirect.com/science/article/pii/S0167819113001166},
	abstract = {… Gauss–Seidel or ILU (incomplete LU decomposition), lie beyond the current capabilities of the framework … Within a single GPU, the size of the mini-partitions is very small, and so … of performance during the incrementing process due to warp divergence on NVIDIA GPUs, but the …},
	journal = {Parallel Computing},
	author = {Mudalige, GR and Giles, MB and Thiyagalingam, J and Reguly, IZ and {...}},
	year = {2013},
	note = {Publisher: Elsevier},
}

@article{PPCG,
	title = {Polyhedral parallel code generation for {CUDA}},
	volume = {9},
	issn = {1544-3566},
	url = {https://doi.org/10.1145/2400682.2400713},
	doi = {10.1145/2400682.2400713},
	abstract = {This article addresses the compilation of a sequential program for parallel execution on a modern GPU. To this end, we present a novel source-to-source compiler called PPCG. PPCG singles out for its ability to accelerate computations from any static control loop nest, generating multiple CUDA kernels when necessary. We introduce a multilevel tiling strategy and a code generation scheme for the parallelization and locality optimization of imperfectly nested loops, managing memory and exposing concurrency according to the constraints of modern GPUs. We evaluate our algorithms and tool on the entire PolyBench suite.},
	number = {4},
	journal = {ACM Trans. Archit. Code Optim.},
	author = {Verdoolaege, Sven and Carlos Juega, Juan and Cohen, Albert and Ignacio Gómez, José and Tenllado, Christian and Catthoor, Francky},
	month = jan,
	year = {2013},
	note = {Number of pages: 23
Place: New York, NY, USA
Publisher: Association for Computing Machinery
tex.articleno: 54
tex.issue\_date: January 2013},
	keywords = {C-to-CUDA, CUDA, GPU, PPCG., Par4All, Polyhedral model, code generation, compilers, loop transformations},
}

@article{OpenTuner,
	title = {{OpenTuner}: {An} extensible framework for program autotuning},
	url = {http://groups.csail.mit.edu/commit/papers/2014/ansel-pact14-opentuner.pdf},
	doi = {10.1145/2628071.2628092},
	journal = {2014 23rd International Conference on Parallel Architecture and Compilation Techniques (PACT)},
	author = {Ansel, Jason and Kamil, Shoaib and Veeramachaneni, Kalyan and Ragan-Kelley, Jonathan and Bosboom, Jeffrey and O’Reilly, Una-May and Amarasinghe, Saman},
	year = {2014},
	pages = {303--315},
}

@article{pop00030,
	title = {Extending a run-time resource management framework to support opencl and heterogeneous systems},
	url = {https://dl.acm.org/doi/abs/10.1145/2556863.2556868},
	abstract = {… The exploration has been performed by MOST, a DSE tool developed in the context of the MULTICUBE project [8]. It is worth to remark that the last objective has been introduced … Auto-tuning SkePU: a Multi-Backend Skeleton Programming Framework for Multi-GPU Systems …},
	journal = {Proceedings of Workshop …},
	author = {Massari, G and Caffarri, C and Bellasi, P and {...}},
	year = {2014},
	note = {Publisher: dl.acm.org},
}

@article{pop00038,
	title = {{SKOPE}: {A} framework for modeling and exploring workload behavior},
	url = {https://dl.acm.org/doi/abs/10.1145/2597917.2597928},
	abstract = {… control flow profiler, which is part of our source-to-source translation tool, provides the … study in Section 6.1, and Listing 7 shows one automatically ex- plored GPU implementation scheme … Our framework there- fore allows users to provide additional information in the form of hints …},
	journal = {Proceedings of the 11th …},
	author = {Meng, J and Wu, X and Morozov, V and Vishwanath, V and {...}},
	year = {2014},
	note = {Publisher: dl.acm.org},
}

@article{stojadinovicMeSATMultipleEncodings2014,
	title = {{meSAT}: multiple encodings of {CSP} to {SAT}},
	volume = {19},
	issn = {1572-9354},
	shorttitle = {{meSAT}},
	url = {https://doi.org/10.1007/s10601-014-9165-7},
	doi = {10.1007/s10601-014-9165-7},
	abstract = {One approach for solving Constraint Satisfaction Problems (CSP) (and related Constraint Optimization Problems (COP)) involving integer and Boolean variables is reduction to propositional satisfiability problem (SAT). A number of encodings (e.g., direct, log, support, order) for this purpose exist as well as specific encodings for some constraints that are often encountered (e.g., cardinality constraints, global constraints). However, there is no single encoding that performs well on all classes of problems and there is a need for a system that supports multiple encodings. We present a system that translates specifications of finite linear CSP problems into SAT instances using several well-known encodings, and their combinations. We also present a methodology for selecting a suitable encoding based on simple syntactic features of the input CSP instance. Thorough evaluation has been performed on large publicly available corpora and our encoding selection method improves upon the efficiency of existing encodings and state-of-the-art tools used in comparison.},
	language = {en},
	number = {4},
	urldate = {2023-08-22},
	journal = {Constraints},
	author = {Stojadinović, Mirko and Marić, Filip},
	month = oct,
	year = {2014},
	keywords = {Algorithm portfolio, CSP, Encoding CSP to SAT, SAT},
	pages = {380--403},
}

@article{pop00044,
	title = {An extensible framework for composing stencils with common scientific computing patterns},
	url = {https://dl.acm.org/doi/abs/10.1145/2686745.2686750},
	abstract = {… 3. Extension to OpenCL and GPUs Our goal was to add support for high-performance GPU imple … Figure 9 shows that two succes- sive applications of a laplacian filter with Sepya+GPU is up … DSELs can be and have been added by develop- ers other than the framework authors …},
	journal = {… of the Second Workshop on Optimizing …},
	author = {Truong, L and Markley, C and Fox, A},
	year = {2014},
	note = {Publisher: dl.acm.org},
}

@article{pop00028,
	title = {A framework for lattice {QCD} calculations on {GPUs}},
	url = {https://ieeexplore.ieee.org/abstract/document/6877336/},
	abstract = {… to calculate properties of the non-perturbative regime of QCD and is an important tool for nuclear … First we will give a very brief overview of the framework and introduce central data types … We used the CUDA toolkit version 5.5 and the NVIDIA UNIX x86-64 Kernel Module version …},
	journal = {2014 IEEE 28th …},
	author = {Winter, FT and Clark, MA and Edwards, RG and {...}},
	year = {2014},
	note = {Publisher: ieeexplore.ieee.org},
}

@book{pop00066,
	title = {High-performance parallel programming framework using template-based static optimization},
	url = {https://www.ideals.illinois.edu/handle/2142/49466},
	abstract = {… GDDR Graphics double data rate GPU Graphics processing unit MIMD Multiple instruction, multiple data … and mainstream GPUs. Despite the distinct design execution units, their … 3.1 Terminologies The basic objects used in the programming framework are called computa …},
	publisher = {ideals.illinois.edu},
	author = {Wu, S},
	year = {2014},
}

@article{pop00048,
	title = {Methods to load balance a {GCR} pressure solver using a stencil framework on multi-and many-core architectures},
	url = {https://www.hindawi.com/journals/sp/2015/648752/abs/},
	abstract = {… currently does not support GPUDirect RDMA to directly exchange data between GPUs located on … data movement between CPU and GPU all arrays are allocated on GPU before executing … The framework provides the Fortran bindings to ease the combination with C++, OpenMP …},
	journal = {Scientific …},
	author = {Ciznicki, M and Kulczewski, M and Kopta, P and {...}},
	year = {2015},
	note = {Publisher: hindawi.com
Type: HTML},
}

@book{ACCTuner,
	address = {Thuwal, SB},
	title = {{ACCTuner}: {OpenACC} auto-tuner for accelerated scientific applications},
	url = {https://doi.org/10.25781/KAUST-K7EKW},
	abstract = {… PATUS [10] is a “Parallel AutoTUned Stencils” framework with tuning performed on … GPU-specific parameters such as block size and loop-unrolling degree. Furthermore … multiple stages (see figure 4.1). First, the auto-tuner goes through a learning phase …},
	publisher = {KAUST Research Repository},
	author = {Alzayer, F},
	year = {2015},
	doi = {10.25781/KAUST-K7EKW},
}

@book{pop00022,
	title = {{ACCTuner}: {OpenACC} auto-tuner for accelerated scientific applications},
	url = {https://repository.kaust.edu.sa/handle/10754/554083},
	abstract = {… PATUS [10] is a “Parallel AutoTUned Stencils” framework with tuning performed on … GPU-specific parameters such as block size and loop-unrolling degree. Furthermore … multiple stages (see figure 4.1). First, the auto-tuner goes through a learning phase …},
	publisher = {repository.kaust.edu.sa},
	author = {Alzayer, F},
	year = {2015},
}

@article{pop00014,
	title = {{FMMTL}: {FMM} {Template} {Library} a generalized framework for kernel matrices},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-10705-9_60},
	abstract = {… In this paper, we review recent development of a parallel, generalized framework and repository for kernel … The hardware used was an Intel Xeon W3670 3.2 GHz CPU and an Nvidia GTX580 GPU … A sparse octree gravitational n-body code that runs entirely on the GPU processor …},
	journal = {Numerical Mathematics and Advanced Applications …},
	author = {Cecka, C and Layton, S},
	year = {2015},
	note = {Publisher: Springer},
}

@book{pop00062,
	title = {A toolkit for building dynamic compilers for array-based languages targeting cpus and gpus},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.7403&rep=rep1&type=pdf},
	abstract = {… isolation with the compiler framework built for one language not benefiting users of other … Ve- lociraptor is designed as a reusable toolkit that can be easily adapted and integrated into … or an automated tool, might simply specify that a particular computation or loop should be …},
	publisher = {Citeseer},
	author = {Garg, R},
	year = {2015},
	note = {Type: PDF},
}

@book{pop00049,
	title = {Autonomic behavioural framework for structural parallelism over heterogeneous multi-core systems.},
	url = {https://core.ac.uk/download/pdf/42535199.pdf},
	abstract = {… 6.4 List of the software used to evaluate the framework overhead on the Scalability … their memory limitations, the speed of processing elements, and I/O bus speed between GPUs … and OpenCL environments supporting hybrid (CPU and GPU) executions are low-level and …},
	publisher = {core.ac.uk},
	author = {Goli, M},
	year = {2015},
	note = {Type: PDF},
}

@article{pop00003,
	title = {{GEMMbench}: a framework for reproducible and collaborative benchmarking of matrix multiplication},
	url = {https://arxiv.org/abs/1511.03742},
	abstract = {… We reused the pipeline functionality of the underlying Col- lective Knowledge framework to conduct experiments un- der … launches a kernel and waits for its completion.13 Table 4 shows the estimated GPU and memory energy con- sumption in Joules across the 3 kernels and …},
	journal = {arXiv preprint arXiv:1511.03742},
	author = {Lokhmotov, A},
	year = {2015},
	note = {Publisher: arxiv.org},
}

@book{pop00053,
	title = {Software defined radio over {CUDA}: integration of {GNU} radio framework with {GPGPU}},
	url = {https://upcommons.upc.edu/handle/2117/78388},
	abstract = {… unique suggestion is to avoid the insertion of CPU GNU Radio blocks between GPU blocks … For sake of simplicity this framework won't be compatible with CUDA device characterized by … This limitation is partially overcame in recent NVIDIA cards with a technology called Hyper-Q …},
	publisher = {upcommons.upc.edu},
	author = {Ribero, M},
	year = {2015},
}

@book{pop00080,
	title = {{FRESH}: a framework for real-world structured grid stencil computations on heterogeneous platforms},
	url = {http://www.caep-scns.ac.cn/up/TR_IAPCM-SCNS-HPC201510_yangy.pdf},
	abstract = {… Fine-Grained Parallel SDN Virtualization Programming Framework … http://docs.nvidia.com/cuda/ cuda-c-programming-guide/ [35] OpenCL … org/opencl [36] Delgado, J. and Gazolla, J. and Clua, E. and Sadjadi, SM A case study on porting scientific applications to GPU/CUDA …},
	publisher = {caep-scns.ac.cn},
	author = {Yang, Y and Zhang, A and Yang, Z},
	year = {2015},
	note = {Type: PDF},
}

@book{Gehrke,
	title = {A framework for performance tuning and analysis on parallel computing platforms},
	url = {http://digital.auraria.edu/content/AA/00/00/37/70/00001/Gehrke_ucdenver_0765D_10608.pdf},
	abstract = {… workload characteristics. Byfl is a tool developed by [134] that reports counter values 12 Page 27 … The optimization framework developed in this dissertation demonstrates the perfor … Several studies demonstrate good approximation of GPU performance using an …},
	publisher = {digital.auraria.edu},
	author = {Gehrke, AS},
	year = {2015},
	note = {Type: PDF},
}

@article{lecun2015deep,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	language = {en},
	number = {7553},
	urldate = {2024-11-29},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	pages = {436--444},
}

@article{pop00078,
	title = {Fast: {A} fast stencil autotuning framework based on an optimal-solution space model},
	url = {https://dl.acm.org/doi/abs/10.1145/2751205.2751214},
	abstract = {… FAST with five important stencil com- putation applications on both an Intel Xeon multicore CPU and an NVIDIA Tesla K20c GPU … 3. AUTOTUNING FRAMEWORK Figure 4 highlights the major constituent parts of FAST, including (1) a feature extractor that characterizes …},
	journal = {Proceedings of the 29th ACM on …},
	author = {Luo, Y and Tan, G and Mo, Z and Sun, N},
	year = {2015},
	note = {Publisher: dl.acm.org},
}

@article{CLTune,
	title = {{CLTune}: {A} generic auto-tuner for {OpenCL} kernels},
	url = {https://ieeexplore.ieee.org/abstract/document/7328205/},
	abstract = {… Examples include tuners for a GPU skeleton programming framework [3], as part of a parallelizing … of convolution, and on the other hand by the recent renewed interest in GPU-based convolution … An auto-tuner can be used to optimize the convolution code for each specific filter …},
	journal = {2015 IEEE 9th International …},
	author = {Nugteren, C and Codreanu, V},
	year = {2015},
	note = {Publisher: IEEE},
}

@book{pop00019,
	title = {A framework for managing shared accelerators in heterogeneous environments.},
	url = {https://pdfs.semanticscholar.org/b85d/2a86ea116167183f02d9ab0007607653e0a8.pdf},
	abstract = {… 10 targeting of portions of an application to specific devices such as GPUs via … node or platform. Therefore, integrating any management framework into an enterprise en … tasks will need to be executed using, for example, vectorised CPU, GPU or FPGA implementations …},
	publisher = {pdfs.semanticscholar.org},
	author = {O'Neill, E},
	year = {2015},
	note = {Type: PDF},
}

@article{pop00072,
	title = {Tuning framework for stencil computation in heterogeneous parallel platforms},
	url = {https://link.springer.com/content/pdf/10.1007/s11227-015-1575-9.pdf},
	abstract = {… We provide a framework tool that takes into account characteristics of both the application and the target … However, the proposed framework still is applica- ble for 3D grids … We omit the representation of host program since we focus essentially on processing on the GPU …},
	journal = {The Journal of …},
	author = {Cheikh, TLB and Aguiar, A and Tahar, S and Nicolescu, G},
	year = {2016},
	note = {Publisher: Springer},
}

@article{CollectiveKnowledge,
	title = {Benchmarking, autotuning and crowdtuning {OpenCL} programs using the {Collective} {Knowledge} framework},
	url = {https://dl.acm.org/doi/abs/10.1145/2909437.2909460},
	abstract = {… Optimizing/modeling behavior b of any object (program, kernel, …) as a function of design and optimization … GEMMbench: a framework for reproducible and collaborative benchmarking of matrix multiplication … Fast convolutional nets with fbfft: A gpu performance evaluation …},
	journal = {… of the 4th International Workshop on OpenCL},
	author = {Lokhmotov, A and Fursin, G},
	year = {2016},
	note = {Publisher: dl.acm.org},
	pages = {1--2},
}

@article{pop00056,
	title = {Daino: a high-level framework for parallel and efficient {AMR} on {GPUs}},
	url = {https://ieeexplore.ieee.org/abstract/document/7877131/},
	abstract = {… This section presents the implementation of the compiler and runtime components of our framework … Alternatively, it is possible to reduce startup time by precompiling the PTX kernels; the ptxas tool provided by the CUDA Toolkit can be used in offline compilation of PTX to …},
	journal = {SC'16: Proceedings of the …},
	author = {Wahib, M and Maruyama, N and Aoki, T},
	year = {2016},
	note = {Publisher: ieeexplore.ieee.org},
}

@article{pop00016,
	title = {{YASK}—{Yet} another stencil kernel: {A} framework for {HPC} stencil code-generation and tuning},
	url = {https://ieeexplore.ieee.org/abstract/document/7836083/},
	abstract = {… et al [8] described a code generation scheme for stencil computations on GPU accelerators, which … The YASK framework described in this paper is built around an extension of the code … automate the tuning and avoid local solutions, YASK provides a meta-tool to automatically …},
	journal = {2016 Sixth International …},
	author = {Yount, C and Tobin, J and Breuer, A and {...}},
	year = {2016},
	note = {Publisher: ieeexplore.ieee.org},
}

@book{pop00058,
	title = {Insightful performance analysis of many-task runtimes through tool-runtime integration},
	url = {http://scholarsbank.uoregon.edu/xmlui/handle/1794/22731},
	abstract = {… actionable performance results. I show how tool-runtime integration can be used to aid programmer understanding of performance characteristics and to provide online … 19 5. Architecture of the AMD Radeon 7000 GPU family … Architecture of the Periscope Tuning Framework …},
	publisher = {scholarsbank.uoregon.edu},
	author = {Chaimov, N},
	year = {2017},
}

@inproceedings{Periscope,
	address = {Koloa, HI, USA},
	title = {Tuning {OpenCL} applications with the periscope tuning framework},
	doi = {10.1109/HICSS.2016.711},
	booktitle = {2016 49th hawaii international conference on system sciences ({HICSS})},
	publisher = {IEEEXplore},
	author = {Bajrovic, E. and Mijakovic, R. and Dokulil, J. and Benkner, S. and Gerndt, M.},
	year = {2016},
	pages = {5752--5761},
}

@article{DASMediumScaleDistributedSystem,
	title = {A medium-scale distributed system for computer science research: {Infrastructure} for the long term},
	volume = {49},
	issn = {1558-0814},
	doi = {10.1109/MC.2016.127},
	abstract = {The Dutch Advanced School for Computing and Imaging has built five generations of a 200-node distributed system over nearly two decades while remaining aligned with the shifting computer science research agenda. The system has supported years of award-winning research, underlining the benefits of investing in a smaller-scale, tailored design.},
	number = {05},
	journal = {Computer},
	author = {Bal, H. and Epema, D. and de Laat, C. and van Nieuwpoort, R. and Romein, J. and Seinstra, F. and Snoek, C. and Wijshoff, H.},
	month = may,
	year = {2016},
	note = {Place: Los Alamitos, CA, USA
Publisher: IEEE Computer Society},
	keywords = {image processing, optical fiber networks, peer-to-peer computing, programming, protocols, supercomputers},
	pages = {54--63},
}

@article{pop00079,
	title = {A performance optimization support framework for gpu-based traffic simulations with negotiating agents},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-30307-9_9},
	abstract = {… To analyze the detailed behaviors of computations in the GPUs, we might need to have a help of GPU-depend detailed profilers to obtain the reason of bottlenecks. To make a strong coupling of such GPU-depend profilers with our framework is future work …},
	journal = {Recent Advances in Agent-based Complex …},
	author = {Sano, Y and Kadono, Y and Fukuta, N},
	year = {2016},
	note = {Publisher: Springer},
}

@book{pop00007,
	title = {{GPRM}: a high performance programming framework for manycore processors},
	url = {http://theses.gla.ac.uk/7312/},
	abstract = {… designs 1 [11] with simpler and more power efficient cores. Another trend in parallel computing was the rise of using GPUs 2 for computationally inten- sive problems … This chapter covers details about the design and implementation of the GPRM framework … kernel are covered …},
	publisher = {theses.gla.ac.uk},
	author = {Tousimojarad, A},
	year = {2016},
}

@book{pop00076,
	title = {{MetaFork}: a compilation framework for concurrency models targeting hardware accelerators},
	url = {https://ir.lib.uwo.ca/etd/4429/},
	abstract = {… Another motivation for such a software tool is comparative implementation with the objec- tive … of all, for portability reasons, the hardware characteristics of the targeted GPU device should … framework is presented mainly in Chap- ter 6. However, the software framework that allows …},
	publisher = {ir.lib.uwo.ca},
	author = {Chen, X},
	year = {2017},
}

@article{pop00017,
	title = {{QUARC}: {An} optimized {DSL} framework using {LLVM}},
	url = {https://dl.acm.org/doi/abs/10.1145/3148173.3148188},
	abstract = {… needed by some prob- lems are minimal and the time to solution is not large, so one should minimize the programming costs by using an expressive scripting tool such as … Each array assignment is called a Quarc Kernel (QK) … QUARC: An Optimized DSL Framework using LLVM …},
	journal = {Proceedings of the Fourth Workshop on …},
	author = {Deb, D and Fowler, RJ and Porterfield, A},
	year = {2017},
	note = {Publisher: dl.acm.org},
}

@article{ATFsecondary,
	title = {{ATF}: {A} generic auto-tuning framework},
	url = {https://ieeexplore.ieee.org/abstract/document/8291912/},
	abstract = {… that is optimized for the target hardware, or he uses an auto-tuning tool to automatically … f/2048.0f , 4.0 ); 41 tuner.Tune(); 42 const auto parameters = tuner.GetBestResult(); 43 … C. OpenTuner search The OpenTuner framework [1] implements various search techniques, eg …},
	journal = {2017 IEEE 19th International …},
	author = {Rasch, A and Haidl, M and Gorlatch, S},
	year = {2017},
	note = {Publisher: ieeexplore.ieee.org},
}

@inproceedings{raschATFGenericAutoTuning2017,
	title = {{ATF}: {A} {Generic} {Auto}-{Tuning} {Framework}},
	shorttitle = {{ATF}},
	doi = {10.1109/HPCC-SmartCity-DSS.2017.9},
	abstract = {We describe the Auto-Tuning Framework (ATF) - a novel generic approach for automatic program optimization by choosing the most suitable values of program parameters, such as number of parallel threads, tile sizes, etc. Our framework combines four advantages over the state-of-the-art autotuning: i) it is generic regarding the programming language, application domain, tuning objective (e.g., high performance and/or low energy consumption), and search technique; ii) it can auto-tune a broader class of applications by allowing tuning parameters to be interdependent, e.g., when one parameter is divisible by another parameter; iii) it allows tuning parameters with substantially larger ranges by implementing an optimized search space generation process; and iv) its interface is arguably simpler than the interfaces of current auto-tuning frameworks. We demonstrate ATF's efficacy by comparing it to the state-of-the-art auto-tuning approaches OpenTuner and CLTune, showing better tuning results with less programmer's effort.},
	booktitle = {2017 {IEEE} 19th {International} {Conference} on {High} {Performance} {Computing} and {Communications}; {IEEE} 15th {International} {Conference} on {Smart} {City}; {IEEE} 3rd {International} {Conference} on {Data} {Science} and {Systems} ({HPCC}/{SmartCity}/{DSS})},
	author = {Rasch, Ari and Haidl, Michael and Gorlatch, Sergei},
	month = dec,
	year = {2017},
	keywords = {Cost function, Energy consumption, Graphics processing units, Kernel, Runtime, Search problems, Tuning},
	pages = {64--71},
}

@article{pop00054,
	title = {Panda: a compiler framework for concurrent {CPU}  {GPU} execution of {3D} stencil computations on {GPU}-accelerated supercomputers},
	url = {https://link.springer.com/content/pdf/10.1007/s10766-016-0454-1.pdf},
	abstract = {… a user-friendly framework, the other goal of Panda is to provide a tool that satisfies … The fundamental assumption of the Panda framework is that 3D stencil computations are executed over … Despite this advantage of OpenACC, the GPU-only code generated by Panda is able to …},
	journal = {International Journal of Parallel …},
	author = {Sourouri, M and Baden, SB and Cai, X},
	year = {2017},
	note = {Publisher: Springer},
}

@article{Dao,
	title = {An auto-tuner for {OpenCL} work-group size on {GPUs}},
	volume = {29},
	url = {https://ieeexplore.ieee.org/abstract/document/8048544/},
	abstract = {… Many studies have been done to tune a set of parame- ters for a specific GPU program [5], [8], [9], [16], [33]. How- ever, our work focuses on a generic auto-tuner of OpenCL programs for GPUs. Ryoo et al … Ansel et al. [1] introduce a framework called OpenTuner to automatically …},
	number = {2},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Dao, TT and Lee, J},
	year = {2017},
	note = {Publisher: IEEE},
	pages = {283 -- 296},
}

@book{floatingpoint_autotuning,
	address = {Columbia, Missouri, USA},
	title = {Performance/accuracy trade-offs of floating-point arithmetic on {NVidia} {GPUs}: from a characterization to an auto-tuner},
	url = {https://mospace.umsystem.edu/xmlui/handle/10355/66752},
	abstract = {… these devices; second, providing insights and criteria that can help the design of tuning assistants for GPU codes; third we design a novel GPU program auto-tuner which improves the hardware utilization and performance … Table III. Hardware configuration of NVidia GPUs GPU …},
	publisher = {MOSpace},
	author = {Surineni, S},
	year = {2017},
}

@article{MicroHH2017,
	title = {{MicroHH} 1.0: {A} computational fluid dynamics code for direct numerical simulation and large-eddy simulation of atmospheric boundary layer flows},
	volume = {10},
	number = {8},
	journal = {Geoscientific Model Development},
	author = {Van Heerwaarden, Chiel C and Van Stratum, Bart JH and Heus, Thijs and Gibbs, Jeremy A and Fedorovich, Evgeni and Mellado, Juan Pedro},
	year = {2017},
	note = {Publisher: Copernicus GmbH},
	pages = {3145--3165},
}

@article{BOAST,
	title = {{BOAST}: {A} metaprogramming framework to produce portable and efficient computing kernels for {HPC} applications},
	url = {https://journals.sagepub.com/doi/abs/10.1177/1094342017718068},
	journal = {The International Journal of High Performance Computing Applications},
	author = {Videau, B and Pouget, K and Genovese, L and Deutsch, T and Komatitsch, D and Desprez, F and Mehau, JF},
	year = {2017},
	note = {Publisher: SAGE Publications},
}

@book{pop00032,
	title = {The {PRiME} {Framework}: {Application}-\& platform-agnostic system management},
	url = {https://eprints.soton.ac.uk/422211/},
	abstract = {… XU3, a heterogeneous multi-core system with two quad-core CPU clusters and a GPU, and a … method, an algorithm that is commonly embedded in real-world applications as a computational kernel for the … [9] H. Hoffmann et al., “A Generalized Software Framework for Accurate …},
	publisher = {eprints.soton.ac.uk},
	author = {Bragg, GML and Balsamo, D and Leech, CR and Merrett, G},
	year = {2018},
}

@misc{intel_GPU,
	title = {Intel’s architecture day 2018: {The} future of core, intel gpus, 10nm, and hybrid x86},
	url = {https://www.anandtech.com/show/13699/intel-architecture-day-2018-core-future-hybrid-x86/5},
	publisher = {AnandTech},
	author = {Cutress, Dr. Ian},
	month = dec,
	year = {2018},
}

@article{pop00041,
	title = {A framework for auto-parallelization and code generation: an integrative case study with legacy {FORTRAN} codes},
	url = {https://dl.acm.org/doi/abs/10.1145/3225058.3225143},
	abstract = {… threads on a multi- or many-core CPU or accelerator/co-processor (eg, GPU or Intel … execution on target de- vices that follow o oad programming models, eg, GPUs and FP … with existing FORTRAN codes and illus- trate how we extend the GLAF programming framework to acco …},
	journal = {Proceedings of the 47th …},
	author = {Krommydas, K and Sathre, P and Sasanka, R and {...}},
	year = {2018},
	note = {Publisher: dl.acm.org},
}

@article{pop00043,
	title = {{UHCL}-{Darknet}: an {OpenCL}-based deep neural network framework for heterogeneous multi-/many-core clusters},
	url = {https://dl.acm.org/doi/abs/10.1145/3225058.3225107},
	abstract = {… than only for the sys- tem with multiple CUDA-enabled GPUs or the CUDA-enabled GPU cluster … Finally, the proposed auto-tuner implemented as the extension of CLtuner [25] by adding a SVM-based runtime … UHCL-Darknet: An OpenCL-based Deep Neural Network Framework …},
	journal = {Proceedings of the 47th International …},
	author = {Liao, L and Li, K and Li, K and Yang, C and Tian, Q},
	year = {2018},
	note = {Publisher: dl.acm.org},
}

@article{pop00059,
	title = {Edgeeye: {An} edge service framework for real-time intelligent video analytics},
	url = {https://dl.acm.org/doi/abs/10.1145/3213344.3213345},
	abstract = {… In conclusion, GPU acceleration is very important to get high-performance inference, and the optimized inference … Nvidia claims their GPUs can de- liver massive performance improvements with the near-zero loss in … We develop the mobile app with the React-native framework …},
	journal = {Proceedings of the 1st International Workshop …},
	author = {Liu, P and Qi, B and Banerjee, S},
	year = {2018},
	note = {Publisher: dl.acm.org},
}

@book{pop00051,
	title = {Efficient implementation and optimization of geometric multigrid operations in the lift framework},
	url = {http://www.lift-project.org/publications/2018/luecke18masterthesis.pdf},
	abstract = {… 1.2.4 The Lift Framework … Programs executed on a GPU are usually written using low-level programming approaches like OpenCL or CUDA … Using a functional approach for generating high-performance code for GPUs has already been proven to be successful for different ap …},
	publisher = {lift-project.org},
	author = {LÜCKE, M},
	year = {2018},
	note = {Type: PDF},
}

@article{Tiramisu,
	title = {Tiramisu: {A} code optimization framework for high performance systems},
	url = {https://pdfs.semanticscholar.org/f276/87603e34506360ea4496aa1642aa2f928237.pdf},
	abstract = {… core parallelism, non-uniform memory (NUMA) hierarchies, clusters, and accelerators like GPUs and FPGAs … Communication (distribution across nodes) Vectorized parallel X86 GPU (Nvidia) … the best as- pects of the two systems to build an optimization framework targeting high …},
	journal = {arXiv preprint arXiv …},
	author = {Baghdadi, R and Ray, J and Romdhane, MB and {...}},
	year = {2018},
	note = {Publisher: pdfs.semanticscholar.org
Type: PDF},
}

@article{balaprakash2017autotuning,
	title = {Autotuning in {High}-{Performance} {Computing} {Applications}},
	volume = {106},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9219, 1558-2256},
	url = {https://ieeexplore.ieee.org/document/8423171/},
	doi = {10.1109/JPROC.2018.2841200},
	number = {11},
	urldate = {2024-11-29},
	journal = {Proceedings of the IEEE},
	author = {Balaprakash, Prasanna and Dongarra, Jack and Gamblin, Todd and Hall, Mary and Hollingsworth, Jeffrey K. and Norris, Boyana and Vuduc, Richard},
	month = nov,
	year = {2018},
	pages = {2068--2083},
}

@article{pop00047,
	title = {{FINN}-r an end-to-end deep-learning framework for fast exploration of quantized neural networks},
	url = {https://dl.acm.org/doi/abs/10.1145/3242897},
	abstract = {… focuses on embed- ded systems with 20W power budgets including the Xilinx ZC706 (FPGA), NVIDIA Jetson TX1 (GPU), TI Keystone II … Similarly, HADDOC2 [3], the synthesis tool described by Wei et al … FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration …},
	journal = {ACM Transactions on …},
	author = {Blott, M and Preußer, TB and Fraser, NJ and Gambardella, G and {...}},
	year = {2018},
	note = {Publisher: dl.acm.org},
}

@inproceedings{CLBlast2018,
	address = {New York, NY, USA},
	series = {{IWOCL} '18},
	title = {{CLBlast}: {A} tuned {OpenCL} {BLAS} library},
	isbn = {978-1-4503-6439-3},
	url = {https://doi.org/10.1145/3204919.3204924},
	doi = {10.1145/3204919.3204924},
	abstract = {This work introduces CLBlast, an open-source BLAS library providing optimized OpenCL routines to accelerate dense linear algebra for a wide variety of devices. It is targeted at machine learning and HPC applications and thus provides a fast matrix-multiplication routine (GEMM) to accelerate the core of many applications (e.g. deep learning, iterative solvers, astrophysics, computational fluid dynamics, quantum chemistry). CLBlast has five main advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested on a large variety of OpenCL devices including less commonly used devices such as embedded and low-power GPUs, 2) it can be explicitly tuned for specific problem-sizes on specific hardware platforms, 3) it can perform operations in half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has an optional CUDA back-end, 5) and it can combine multiple operations in a single batched routine, accelerating smaller problems significantly. This paper describes the library and demonstrates the advantages of CLBlast experimentally for different use-cases on a wide variety of OpenCL hardware.},
	booktitle = {Proceedings of the international workshop on {OpenCL}},
	publisher = {Association for Computing Machinery},
	author = {Nugteren, Cedric},
	year = {2018},
	note = {Number of pages: 10
Place: Oxford, United Kingdom
tex.articleno: 5},
	keywords = {Auto-Tuning, BLAS, Batched GEMM, CUDA, Deep Learning, FP16, GEMM, GPU, HPC, OpenCL},
}

@article{CodingAnts,
	title = {Coding {Ants}: {Optimization} of {GPU} code using ant colony optimization},
	volume = {54},
	issn = {1477-8424},
	url = {http://www.sciencedirect.com/science/article/pii/S1477842418300137},
	doi = {https://doi.org/10.1016/j.cl.2018.05.003},
	abstract = {This article proposes the Coding Ants framework, an approach for auto-tuning which uses ant colony optimization to find a sequence of code optimizations for GPU architectures. The proposed framework is built as an extension to the PPCG compiler, a source-to-source code generator based on the polyhedral model and specializing in the generation of CUDA code. As such, the Coding Ants framework is able to use the polyhedral abstraction to represent a large space of possible transformations. Several optimizations are also presented which have not been included in any previous GPU auto-tuning system. The proposed framework also extends the traditional ant colony optimization algorithm to include performance metrics as well as a regression tree analysis to segment the search space. We evaluate the framework on the PolyBench suite and compare the performance of three levels of optimization that transfer increasing control to the Coding Ants framework from the PPCG cost model.},
	journal = {Computer Languages, Systems \& Structures},
	author = {Papenhausen, Eric and Mueller, Klaus},
	year = {2018},
	keywords = {Ant colony optimization, Automatic optimization, Autotuning, CUDA, GPU optimization, Polyhedral model},
	pages = {119 -- 138},
}

@article{ATF,
	title = {{ATF}: {A} generic directive‐based auto‐tuning framework},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4423},
	abstract = {… In this paper, we propose the Auto‐Tuning Framework (ATF), which combines the following advantages over the … The kernel is executed on a device (eg, a GPU) in parallel by several Work … that is optimized for the target hardware, or he uses an auto‐tuning tool to automatically …},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Rasch, A and Gorlatch, S},
	year = {2018},
	note = {Publisher: Wiley Online Library},
}

@article{ashouri2018survey,
	title = {A {Survey} on {Compiler} {Autotuning} using {Machine} {Learning}},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3197978},
	doi = {10.1145/3197978},
	abstract = {Since the mid-1990s, researchers have been trying to use machine-learning-based approaches to solve a number of different compiler optimization problems. These techniques primarily enhance the quality of the obtained results and, more importantly, make it feasible to tackle two main compiler optimization problems: optimization selection (choosing which optimizations to apply) and phase-ordering (choosing the order of applying optimizations). The compiler optimization space continues to grow due to the advancement of applications, increasing number of compiler optimizations, and new target architectures. Generic optimization passes in compilers cannot fully leverage newly introduced optimizations and, therefore, cannot keep up with the pace of increasing options. This survey summarizes and classifies the recent advances in using machine learning for the compiler optimization field, particularly on the two major problems of (1) selecting the best optimizations, and (2) the phase-ordering of optimizations. The survey highlights the approaches taken so far, the obtained results, the fine-grain classification among different approaches, and finally, the influential papers of the field.},
	language = {en},
	number = {5},
	urldate = {2024-11-29},
	journal = {ACM Computing Surveys},
	author = {Ashouri, Amir H. and Killian, William and Cavazos, John and Palermo, Gianluca and Silvano, Cristina},
	month = sep,
	year = {2019},
	pages = {1--42},
}

@article{pop00001,
	title = {{KLARAPTOR}: a tool for dynamically finding optimal kernel launch parameters targeting {CUDA} programs},
	url = {https://arxiv.org/abs/1911.02373},
	abstract = {… tool is built in the C language, making use of the LLVM Pass Framework (see Section VC … Lastly, the hardware parameters are values specific to the target GPU, for example, memory bandwidth, the … calls will interfere with later CUDA driver API calls used by our tool, for example …},
	journal = {arXiv preprint arXiv …},
	author = {Brandt, A and Mohajerani, D and Maza, MM and Paudel, J and {...}},
	year = {2019},
	note = {Publisher: arxiv.org},
}

@article{pop00067,
	title = {A massively scalable distributed multigrid framework for nonlinear marine hydrodynamics},
	url = {https://journals.sagepub.com/doi/abs/10.1177/1094342019826662},
	abstract = {… Access Options. You can be signed in via any or all of the methods shown below at the same time. My Profile … A massively scalable distributed multigrid framework for nonlinear marine hydrodynamics. Stefan Lemvig Glimberg, Allan Peter Engsig-Karup, and Luke N Olson …},
	journal = {… International Journal of …},
	author = {Glimberg, SL and Engsig-Karup, AP and {...}},
	year = {2019},
	note = {Publisher: journals.sagepub.com},
}

@article{pop00052,
	title = {{DM}-{HEOM}: a portable and scalable solver-framework for the hierarchical equations of motion},
	url = {https://ieeexplore.ieee.org/abstract/document/8425516/},
	abstract = {… expert starts with developing a prototype algo- rithm in a high-level tool, in our … Similarly, GPU implementations work better with NDRanges and work-group shapes reflecting the shape of the … specific runtime set- tings from the physics problem, the apps in our framework take two …},
	journal = {2018 IEEE International …},
	author = {Noack, M and Reinefeld, A and Kramer, T and {...}},
	year = {2018},
	note = {Publisher: ieeexplore.ieee.org},
}

@incollection{bjornerProgrammingZ32019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Programming {Z3}},
	isbn = {978-3-030-17601-3},
	url = {https://doi.org/10.1007/978-3-030-17601-3_4},
	abstract = {This tutorial provides a programmer’s introduction to the Satisfiability Modulo Theories Solver Z3. It describes how to use Z3 through scripts, provided in the Python scripting language, and it describes several of the algorithms underlying the decision procedures within Z3. It aims to broadly cover almost all available features of Z3 and the essence of the underlying algorithms.},
	language = {en},
	urldate = {2023-08-23},
	booktitle = {Engineering {Trustworthy} {Software} {Systems}: 4th {International} {School}, {SETSS} 2018, {Chongqing}, {China}, {April} 7–12, 2018, {Tutorial} {Lectures}},
	publisher = {Springer International Publishing},
	author = {Bjørner, Nikolaj and de Moura, Leonardo and Nachmanson, Lev and Wintersteiger, Christoph M.},
	editor = {Bowen, Jonathan P. and Liu, Zhiming and Zhang, Zili},
	year = {2019},
	doi = {10.1007/978-3-030-17601-3_4},
	pages = {148--201},
}

@article{pop00081,
	title = {{AutoFFT}: a template-based {FFT} codes auto-generation framework for {ARM} and {X86} cpus},
	url = {https://dl.acm.org/doi/abs/10.1145/3295500.3356138},
	abstract = {… Although the factors that affect the FFT performance on GPUs can be quite different than those … writing optimized butterfly kernels that exploit the underlying hardware features, such as GPU memory hierarchy … AutoFFT: A Template-Based FFT Codes Auto-Generation Framework …},
	journal = {Proceedings of the …},
	author = {Li, Z and Jia, H and Zhang, Y and Chen, T and Yuan, L and Cao, L and {...}},
	year = {2019},
	note = {Publisher: dl.acm.org},
}

@article{vanwerkhovenKernelTunerSearchoptimizing2019,
	title = {Kernel {Tuner}: {A} search-optimizing {GPU} code auto-tuner},
	volume = {90},
	issn = {0167-739X},
	shorttitle = {Kernel {Tuner}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X18313359},
	doi = {10.1016/j.future.2018.08.004},
	abstract = {A very common problem in GPU programming is that some combination of thread block dimensions and other code optimization parameters, like tiling or unrolling factors, results in dramatically better performance than other kernel configurations. To obtain highly-efficient kernels it is often required to search vast and discontinuous search spaces that consist of all possible combinations of values for all tunable parameters. This paper presents Kernel Tuner, an easy-to-use tool for testing and auto-tuning OpenCL, CUDA, and C kernels with support for many search optimization algorithms that accelerate the tuning process. This paper introduces the application of many new solvers and global optimization algorithms for auto-tuning GPU applications. We demonstrate that Kernel Tuner can be used in a wide range of application scenarios and drastically decreases the time spent tuning, e.g. tuning a GEMM kernel on AMD Vega Frontier Edition 71.2x faster than brute force search.},
	language = {en},
	urldate = {2023-07-19},
	journal = {Future Generation Computer Systems},
	author = {van Werkhoven, Ben},
	month = jan,
	year = {2019},
	keywords = {Auto-tuning, GPU computing, Parallel programming, Performance optimization, Software development},
	pages = {347--358},
}

@article{pop00069,
	title = {Suraa: {A} novel method and tool for loadbalanced and coalesced spmv computations on gpus},
	url = {https://www.mdpi.com/2076-3417/9/5/947},
	abstract = {… We implement the SURAA method as a tool and compare its performance with the de facto … CUDA 5. It introduced nested parallelism with the help of nested kernel calls from the GPUs. In the earlier GPU parallel computing model, kernels were invoked in sequence from the host …},
	journal = {Applied Sciences},
	author = {Muhammed, T and Mehmood, R and Albeshri, A and Katib, I},
	year = {2019},
	note = {Publisher: mdpi.com},
}

@article{Performance_Portability_index,
	title = {Implications of a metric for performance portability},
	volume = {92},
	url = {https://arxiv.org/pdf/1611.07409.pdf},
	doi = {10.1016/j.future.2017.08.007},
	journal = {Future Generation Computer Systems},
	author = {Pennycook, S.J. and Sewall, J.D. and Lee, V.W.},
	month = mar,
	year = {2019},
	pages = {947--958},
}

@article{pop00012,
	title = {Kernel {Tuner}: {A} search-optimizing {GPU} code auto-tuner},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X18313359},
	abstract = {… This paper presents Kernel Tuner, an easy-to-use tool for testing and auto-tuning CUDA … In this evaluation, we present a selection of the applications for which we have used Kernel Tuner … The performance results have been obtained using the NVidia GTX Titan X GPU and the …},
	journal = {Future Generation Computer Systems},
	author = {van Werkhoven, B},
	year = {2019},
	note = {Publisher: Elsevier
Type: HTML},
}

@article{pop00008,
	title = {Horus: {A} modular {GPU} emulator framework},
	url = {https://ieeexplore.ieee.org/abstract/document/9238604/},
	abstract = {… extend. Our tool, Horus, is currently a functional simulator (ie em- ulator) … McCardwell. MGPUSim: enabling multi-GPU performance modeling and optimization … Keckler. Nvbit: A Dynamic Binary Instrumentation Framework for NVIDIA GPUs …},
	journal = {… on Performance Analysis of Systems and …},
	author = {Elhelw, AS and Pai, S},
	year = {2020},
	note = {Publisher: ieeexplore.ieee.org},
}

@article{pop00035,
	title = {The {AllScale} framework architecture},
	url = {https://www.sciencedirect.com/science/article/pii/S0167819120300417},
	abstract = {… for distributing computations among heterogeneous hardware, eg by providing CPU and GPU implementations of … examples of data structures that can be managed in this framework include other … redundant boilerplate code introduced due to a lack of automated tool support …},
	journal = {Parallel Computing},
	author = {Jordan, H and Gschwandtner, P and Thoman, P and Zangerl, P and {...}},
	year = {2020},
	note = {Publisher: Elsevier},
}

@article{pop00042,
	title = {{AN5D}: automated stencil framework for high-degree temporal blocking on {GPUs}},
	url = {https://dl.acm.org/doi/abs/10.1145/3368826.3377904},
	abstract = {… Keywords Stencil Computation, GPU, Automatic Code Generation, Temporal Blocking … Since our framework requires double-buffered stencil codes that use the modulo operator (t},
	journal = {… and Optimization},
	author = {Matsumura, K and Zohouri, HR and Wahib, M and Endo, T and {...}},
	year = {2020},
	note = {Publisher: dl.acm.org},
}

@article{pop00077,
	title = {A hybrid framework for fast and accurate gpu performance estimation through source-level analysis and trace-based simulation},
	url = {https://ieeexplore.ieee.org/abstract/document/8675207/},
	abstract = {… The framework mainly contains two modules, ie the source-level analysis and the subsequent trace … 2) Execution trace generation: Let's first consider how GPU walks along the CFG to execute the … For Nvidia GPUs, each OpenCL work item instance is mapped to a thread and a …},
	journal = {2019 IEEE International …},
	author = {Wang, X and Huang, K and Knoll, A and {...}},
	year = {2019},
	note = {Publisher: ieeexplore.ieee.org},
}

@article{pop00060,
	title = {A large-scale framework for symbolic implementations of seismic inversion algorithms in {Julia}},
	url = {https://library.seg.org/doi/abs/10.1190/geo2018-0174.1},
	abstract = {… computing, which offers optional typing and function overloading based on input argument types (multiple … a variety of concrete examples, we underline what sets our framework apart from … algorithms to large 3D problems with more than 100 million unknown model parameters. • …},
	journal = {Geophysics},
	author = {Witte, PA and Louboutin, M and Kukreja, N and Luporini, F and Lange, M and {...}},
	year = {2019},
	note = {Publisher: library.seg.org},
}

@article{pop00031,
	title = {Caspmv: {A} customized and accelerative spmv framework for the sunway taihulight},
	url = {https://ieeexplore.ieee.org/abstract/document/8674603/},
	abstract = {… [30] proposed the Segmented Interleave Combination (SIC) storage format to combine a certain amount of CSR rows to form a new SIC row that is well-suited to GPU architec- ture … Then, based on the statistical model, the CASpMV framework provides an auto-tuner for the …},
	journal = {IEEE Transactions on …},
	author = {Xiao, G and Li, K and Chen, Y and He, W and {...}},
	year = {2019},
	note = {Publisher: ieeexplore.ieee.org},
}

@book{pop00002,
	title = {Designing a modern skeleton programming framework for parallel and heterogeneous systems},
	url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1472256},
	abstract = {… 136 10.2.1 Modernize the SkePU tuner … eg in conjunction with HLPP 2019 and MCC 2019, and in teaching through the course TDDD56: Multicore and GPU programming, and … Chapter 3 provides an initial concise overview of the SkePU framework, the main topic of the thesis …},
	publisher = {diva-portal.org},
	author = {Ernstsson, A},
	year = {2020},
}

@article{pop00075,
	title = {{DCA}++: {A} software framework to solve correlated electron problems with modern quantum cluster methods},
	url = {https://www.sciencedirect.com/science/article/pii/S0010465519300086},
	abstract = {… COVID-19 campus closures: see options for getting or … the first open release of the DCA++ project, a high-performance research software framework to solve … portable performance on conventional and emerging new architectures, such as hybrid CPU–GPU, sustaining multiple …},
	journal = {Computer Physics …},
	author = {Hähner, UR and Alvarez, G and Maier, TA and Solcà, R and {...}},
	year = {2020},
	note = {Publisher: Elsevier
Type: HTML},
}

@misc{nvidia_datacenter_revenue_surpasses_gaming,
	title = {Nvidia’s datacenter revenue has surpassed gaming for the first time},
	url = {https://www.extremetech.com/extreme/314063-nvidias-datacenter-revenue-has-surpassed-gaming-for-the-first-time-in-company-history},
	journal = {ExtremeTech},
	author = {Hruska, Joel},
	month = aug,
	year = {2020},
	note = {Authority: ExtremeTech},
}

@misc{gpus_in_datacenter,
	title = {The datacenter has an appetite for gpu compute},
	url = {https://www.nextplatform.com/2020/02/15/the-datacenter-has-an-appetite-for-gpu-compute/},
	journal = {The Next Platform},
	author = {Morgan, Timothy Prickett},
	month = feb,
	year = {2020},
	note = {Authority: The Next Platform},
}

@book{fpga_autotuning,
	address = {Fayetteville, Arkansas, USA},
	title = {An automated design space exploration tool for {OpenCL}-based implementations on fpgas using machine learning},
	url = {http://search.proquest.com/openview/b4ee3dd5924d02937b8cc1ee7c76d5bc/1?pq-origsite=gscholar&cbl=18750&diss=y},
	abstract = {… The device code is portable and platform-independent. So, FPGAs and GPUs can use the same kernel … framework popular with hardware engineers to accelerate the hardware designs [19]. Page 26. 6 … This tool will also find the optimized design with the minimum …},
	publisher = {search.proquest.com},
	author = {Naher, J},
	year = {2020},
}

@article{KTTBenchmark,
	title = {A benchmark set of highly-efficient {CUDA} and {OpenCL} kernels and its dynamic autotuning with {Kernel} {Tuning} {Toolkit}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X19327360},
	abstract = {… The OpenTuner [5], another similar tuner, is a more generic and low-level tool: it allows … section, we introduce the main architectural concepts and the API of the Kernel Tuning Toolkit … KTT framework allows sharing tuning parameters among kernels by using kernel compositions …},
	journal = {Future Generation …},
	author = {Petrovič, F and Střelák, D and Hozzová, J and Ol'ha, J and {...}},
	year = {2020},
	note = {Publisher: Elsevier},
}

@misc{intel_GPU_2,
	title = {Intel enters the laptop discrete {GPU} market with {Xe} {Max}},
	url = {https://arstechnica.com/gadgets/2020/11/intel-enters-the-laptop-discrete-gpu-market-with-xe-max/?comments=1},
	publisher = {Ars Technica},
	author = {Salter, Jim},
	month = nov,
	year = {2020},
}

@inproceedings{lessonsLearnedGPU2020,
	title = {Lessons learned in a decade of research software engineering gpu applications},
	booktitle = {International conference on computational science},
	publisher = {Springer},
	author = {van Werkhoven, Ben and Palenstijn, Willem Jan and Sclocco, Alessio},
	year = {2020},
	pages = {399--412},
}

@misc{nvidia-ampere-architecture-whitepaper,
	title = {{NVIDIA} {A100} {Tensor} {Core} {GPU} {Architecture}},
	url = {https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf},
	abstract = {Unprecedented Acceleration At Every Scale},
	language = {English},
	urldate = {2024-03-11},
	year = {2020},
}

@article{heldens2020landscape,
	title = {The {Landscape} of {Exascale} {Research}: {A} {Data}-{Driven} {Literature} {Analysis}},
	volume = {53},
	issn = {0360-0300, 1557-7341},
	shorttitle = {The {Landscape} of {Exascale} {Research}},
	url = {https://dl.acm.org/doi/10.1145/3372390},
	doi = {10.1145/3372390},
	abstract = {The next generation of supercomputers will break the exascale barrier. Soon we will have systems capable of at least one quintillion (billion billion) floating-point operations per second (10
              18
              FLOPS). Tremendous amounts of work have been invested into identifying and overcoming the challenges of the exascale era. In this work, we present an overview of these efforts and provide insight into the important trends, developments, and exciting research opportunities in exascale computing. We use a three-stage approach in which we (1) discuss various exascale landmark studies, (2) use data-driven techniques to analyze the large collection of related literature, and (3) discuss eight research areas in depth based on influential articles. Overall, we observe that great advancements have been made in tackling the two primary exascale challenges: energy efficiency and fault tolerance. However, as we look forward, we still foresee two major concerns: the lack of suitable programming tools and the growing gap between processor performance and data bandwidth (i.e., memory, storage, networks). Although we will certainly reach exascale soon, without additional research, these issues could potentially limit the applicability of exascale computing.},
	language = {en},
	number = {2},
	urldate = {2024-11-29},
	journal = {ACM Computing Surveys},
	author = {Heldens, Stijn and Hijma, Pieter and Werkhoven, Ben Van and Maassen, Jason and Belloum, Adam S. Z. and Van Nieuwpoort, Rob V.},
	month = mar,
	year = {2021},
	pages = {1--43},
}

@article{pop00071,
	title = {Hybrid {CPU}–{GPU} execution support in the skeleton programming framework {SkePU}},
	url = {https://link.springer.com/article/10.1007/s11227-019-02824-7},
	abstract = {… This means that a GPU will go idle if the first and second steps are to be made synchronized with the CPU, as it will finish its second step … [11] in their Qilin framework, although our … Our tuner builds two execution time models, one for the CPU and one for the accelerator backend …},
	journal = {The Journal of Supercomputing},
	author = {Öhberg, T and Ernstsson, A and Kessler, C},
	year = {2020},
	note = {Publisher: Springer
Type: HTML},
}

@misc{gpu_marketshare,
	title = {Nvidia increases its dedicated {GPU} market share to 80\%},
	url = {https://www.techspot.com/news/86532-nvidia-now-holds-80-dedicated-gpu-market.html},
	publisher = {TechSpot},
	author = {Thubron, Rob},
	month = aug,
	year = {2020},
}

@inproceedings{liuGPTuneMultitaskLearning2021,
	address = {New York, NY, USA},
	series = {{PPoPP} '21},
	title = {{GPTune}: {Multitask} {Learning} for {Autotuning} {Exascale} {Applications}},
	isbn = {978-1-4503-8294-6},
	url = {https://doi.org/10.1145/3437801.3441621},
	doi = {10.1145/3437801.3441621},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Yang and Sid-Lakhdar, Wissam M. and Marques, Osni and Zhu, Xinran and Meng, Chang and Demmel, James W. and Li, Xiaoye S.},
	year = {2021},
	note = {event-place: Virtual Event, Republic of Korea},
	keywords = {autotuning, bayesian optimization, exascale computing project, machine learning, multitask learning},
	pages = {234--246},
}

@article{searchspaceATF,
	title = {Efficient auto-tuning of parallel programs with interdependent tuning parameters via auto-tuning framework ({ATF})},
	volume = {18},
	issn = {1544-3566},
	url = {https://doi.org/10.1145/3427093},
	doi = {10.1145/3427093},
	abstract = {Auto-tuning is a popular approach to program optimization: it automatically finds good configurations of a program’s so-called tuning parameters whose values are crucial for achieving high performance for a particular parallel architecture and characteristics of input/output data. We present three new contributions of the Auto-Tuning Framework (ATF), which enable a key advantage in general-purpose auto-tuning: efficiently optimizing programs whose tuning parameters have interdependencies among them. We make the following contributions to the three main phases of general-purpose auto-tuning: (1) ATF generates the search space of interdependent tuning parameters with high performance by efficiently exploiting parameter constraints; (2) ATF stores such search spaces efficiently in memory, based on a novel chain-of-trees search space structure; (3) ATF explores these search spaces faster, by employing a multi-dimensional search strategy on its chain-of-trees search space representation. Our experiments demonstrate that, compared to the state-of-the-art, general-purpose auto-tuning frameworks, ATF substantially improves generating, storing, and exploring the search space of interdependent tuning parameters, thereby enabling an efficient overall auto-tuning process for important applications from popular domains, including stencil computations, linear algebra routines, quantum chemistry computations, and data mining algorithms.},
	number = {1},
	journal = {ACM Trans. Archit. Code Optim.},
	author = {Rasch, Ari and Schulze, Richard and Steuwer, Michel and Gorlatch, Sergei},
	month = jan,
	year = {2021},
	note = {Number of pages: 26
Place: New York, NY, USA
Publisher: Association for Computing Machinery
tex.articleno: 1
tex.issue\_date: March 2021},
	keywords = {Auto-tuning, interdependent tuning parameters, parallel programs},
}

@article{ATF2,
	title = {Efficient auto-tuning of parallel programs with interdependent tuning parameters via auto-tuning framework ({ATF})},
	volume = {18},
	issn = {1544-3566},
	url = {https://doi-org.vu-nl.idm.oclc.org/10.1145/3427093},
	doi = {10.1145/3427093},
	number = {1},
	journal = {ACM Trans. Archit. Code Optim.},
	author = {Rasch, Ari and Schulze, Richard and Steuwer, Michel and Gorlatch, Sergei},
	month = jan,
	year = {2021},
	note = {Number of pages: 26
Place: New York, NY, USA
Publisher: Association for Computing Machinery
tex.articleno: 1
tex.issue\_date: January 2021},
	keywords = {Auto-tuning, interdependent tuning parameters, parallel programs},
}

@misc{prudhommePychocoPythonBindings,
	title = {pychoco: {Python} bindings to the {Choco} {Constraint} {Programming} solver},
	copyright = {BSD License},
	shorttitle = {pychoco},
	author = {Prud'homme, Charles, Dimitri Justeau-Allaire},
	month = oct,
	year = {2022},
	keywords = {Documentation - Sphinx, Scientific/Engineering, Scientific/Engineering - Artificial Intelligence, Scientific/Engineering - Mathematics, Software Development - Libraries, Software Development - Libraries - Java Libraries, Software Development - Libraries - Python Modules, artificial intelligence,, combinatorics, constraint programming,, graphs,, optimization,},
}

@inproceedings{PMT2022,
	title = {{PMT}: {Power} measurement toolkit},
	doi = {10.1109/HUST56722.2022.00011},
	booktitle = {2022 {IEEE}/{ACM} international workshop on {HPC} user support tools ({HUST})},
	author = {Corda, Stefano and Veenboer, Bram and Tolley, Emma},
	year = {2022},
	pages = {44--47},
}

@article{filipovicUsingHardwarePerformance2022,
	title = {Using hardware performance counters to speed up autotuning convergence on {GPUs}},
	volume = {160},
	issn = {07437315},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0743731521001945},
	doi = {10.1016/j.jpdc.2021.10.003},
	language = {en},
	urldate = {2022-10-27},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Filipovič, Jiří and Hozzová, Jana and Nezarat, Amin and Ol'ha, Jaroslav and Petrovič, Filip},
	month = feb,
	year = {2022},
	pages = {16--35},
}

@article{schoonhovenBenchmarkingOptimizationAlgorithms2022,
	title = {Benchmarking optimization algorithms for auto-tuning {GPU} kernels},
	issn = {1089-778X, 1089-778X, 1941-0026},
	url = {http://arxiv.org/abs/2210.01465},
	doi = {10.1109/TEVC.2022.3210654},
	abstract = {Recent years have witnessed phenomenal growth in the application, and capabilities of Graphical Processing Units (GPUs) due to their high parallel computation power at relatively low cost. However, writing a computationally efficient GPU program (kernel) is challenging, and generally only certain specific kernel configurations lead to significant increases in performance. Auto-tuning is the process of automatically optimizing software for highly-efficient execution on a target hardware platform. Auto-tuning is particularly useful for GPU programming, as a single kernel requires re-tuning after code changes, for different input data, and for different architectures. However, the discrete, and non-convex nature of the search space creates a challenging optimization problem. In this work, we investigate which algorithm produces the fastest kernels if the time-budget for the tuning task is varied. We conduct a survey by performing experiments on 26 different kernel spaces, from 9 different GPUs, for 16 different evolutionary black-box optimization algorithms. We then analyze these results and introduce a novel metric based on the PageRank centrality concept as a tool for gaining insight into the difficulty of the optimization problem. We demonstrate that our metric correlates strongly with observed tuning performance.},
	urldate = {2022-10-31},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Schoonhoven, Richard and van Werkhoven, Ben and Batenburg, Kees Joost},
	year = {2022},
	note = {arXiv:2210.01465 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Graphics, Computer Science - Performance},
	pages = {1--1},
}

@article{schoonhovenGoingGreenOptimizing2022,
	title = {Going green: optimizing {GPUs} for energy efficiency through model-steered auto-tuning},
	shorttitle = {Going green},
	url = {https://ieeexplore.ieee.org/document/10024022/},
	doi = {10.1109/PMBS56514.2022.00010},
	abstract = {Graphics Processing Units (GPUs) have revolutionized the computing landscape over the past decade. However, the growing energy demands of data centres and computing facilities equipped with GPUs come with significant capital and environmental costs. The energy consumption of GPU applications greatly depend on how well they are optimized. Auto-tuning is an effective and commonly applied technique of finding the optimal combination of algorithm, application, and hardware parameters to optimize performance of a GPU application. In this paper, we introduce new energy monitoring and optimization capabilities in Kernel Tuner, a generic auto-tuning tool for GPU applications. These capabilities enable us to investigate the difference between tuning for execution time and various approaches to improve energy efficiency, and investigate the differences in tuning difficulty. Additionally, our model for GPU power consumption greatly reduces the large tuning search space by providing clock frequencies for which a GPU is likely most energy efficient.},
	urldate = {2024-01-12},
	journal = {2022 IEEE/ACM International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)},
	author = {Schoonhoven, Richard and Veenboer, Bram and Van Werkhoven, Ben and Batenburg, K. Joost},
	month = nov,
	year = {2022},
	note = {Conference Name: 2022 IEEE/ACM International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)
ISBN: 9781665451857
Place: Dallas, TX, USA
Publisher: IEEE},
	pages = {48--59},
}

@misc{teamPySMTSolveragnosticLibrary,
	title = {{PySMT}: {A} solver-agnostic library for {SMT} {Formulae} manipulation and solving},
	copyright = {APACHE},
	shorttitle = {{PySMT}},
	url = {http://www.pysmt.org},
	urldate = {2023-08-22},
	author = {Team, PySMT},
	month = may,
	year = {2022},
}

@misc{KernelTunerDashboard2023,
	title = {Kernel {Tuner} {Dashboard}},
	copyright = {Apache-2.0},
	url = {https://github.com/KernelTuner/dashboard},
	abstract = {KTdashboard allows you to monitor, analyze, and visualize an active or completed auto-tuning run of Kernel Tuner},
	urldate = {2024-03-13},
	publisher = {Kernel Tuner},
	author = {{Ben van Werkhoven}},
	month = oct,
	year = {2023},
	note = {original-date: 2022-02-04T23:52:24Z},
}

@misc{RuffLinter,
	title = {Ruff: {An} extremely fast {Python} linter, written in {Rust}.},
	shorttitle = {Ruff},
	url = {https://github.com/astral-sh/ruff},
	abstract = {Ruff aims to be orders of magnitude faster than alternative tools while integrating more functionality behind a single, common interface.

Ruff can be used to replace Flake8 (plus dozens of plugins), isort, pydocstyle, yesqa, eradicate, pyupgrade, and autoflake, all while executing tens or hundreds of times faster than any individual tool.},
	urldate = {2023-09-13},
	author = {{Charlie Marsh}},
	month = sep,
	year = {2023},
}

@misc{BenchmarkingSuiteKerneltuners,
	title = {Towards a {Benchmarking} {Suite} for {Kerneltuners} (accepted at {iWAPT} 2023)},
	url = {https://www.overleaf.com/project/638e0716ca3dc21d79f564ba},
	abstract = {As computing system become more complex combining CPUs and GPUs, it is becoming harder and harder for programmers to keep their codes optimized as the hardware gets updated. Autotuners try to alleviate this by hiding as many architecture-based optimization details as possible from the end-user, so that the code can be used efficiently across different generations of systems. Several autotuning frameworks have emerged, but a comparative analysis between
these related works is scarce, owing to the significant manual
effort required to porting a tunable kernel from one tuner
another. 

\%***We introduce a new benchmark suite for evaluating the performance of 
In this article we introduce a new benchmark suite for evaluating the performance of 
\%**optimization algorithms in modern systems using GPUs. The suite 
optimization algorithms used by modern autotuners targeting GPUs. The suite 
contains tunable GPU kernels that are representative of real-world applications, allowing for comparisons between optimization algorithms and the examination of code optimization, search space difficulty, and performance portability. Our framework facilitates easy integration of new autotuners and benchmarks by defining a shared problem interface.

\%**The benchmark suite is analyzed based on five characteristics: 
Our benchmark suite is evaluated based on five characteristics: 
convergence rate, local minima centrality, optimal speedup, 
\%*** adding commonly used abbreviation :-)
Permutation Feature Importance (PFI), and performance portability. The results show that optimization parameters greatly impact performance and the need for global optimization. The importance of each parameter is consistent across GPU architectures, however, the specific values need to be optimized for each architecture.

\%The benchmarking suite is analyzed using five key characteristics including convergence rate, local minima centrality, optimal speedup, Permutation Feature Importance, and performance portability. Results show that optimization parameters have a significant impact on performance and the need for global optimization. The importance of each parameter is consistent across GPU architectures but specific values need to be optimized for the target architecture.

Our portability study highlights the crucial importance of autotuning each application for a specific target architecture. The results reveal that simply transferring the optimal configuration from one architecture to another can result in a performance ranging from 58.5{\textbackslash}\% to 99.9{\textbackslash}\% of the optimal performance, depending on the GPU architecture. This highlights the importance of autotuning in modern computing systems and the value of our benchmark suite in facilitating the study of optimization algorithms and their effectiveness in achieving optimal performance for specific target architectures.},
	language = {en},
	urldate = {2023-02-06},
	author = {{Jacob O. Tørring} and {Ben van Werkhoven} and {Filip Petrovič} and {Floris-Jan Willemsen} and {Jiří Filipovič} and {Anne C. Elster}},
	month = jan,
	year = {2023},
}

@misc{NoxTestAutomation,
	title = {Nox: {Flexible} test automation for {Python}},
	shorttitle = {Nox},
	url = {https://github.com/wntrblm/nox},
	abstract = {Nox is a command-line tool that automates testing in multiple Python environments, similar to tox. Unlike tox, Nox uses a standard Python file for configuration.},
	urldate = {2023-09-13},
	author = {{Thea Flowers}},
	month = apr,
	year = {2023},
}

@incollection{lurati2024bringing,
	address = {Cham},
	title = {Bringing {Auto}-{Tuning} to {HIP}: {Analysis} of {Tuning} {Impact} and {Difficulty} on {AMD} and {Nvidia} {GPUs}},
	volume = {14801},
	isbn = {978-3-031-69576-6 978-3-031-69577-3},
	shorttitle = {Bringing {Auto}-{Tuning} to {HIP}},
	url = {https://link.springer.com/10.1007/978-3-031-69577-3_7},
	language = {en},
	urldate = {2024-11-29},
	booktitle = {Euro-{Par} 2024: {Parallel} {Processing}},
	publisher = {Springer Nature Switzerland},
	author = {Lurati, Milo and Heldens, Stijn and Sclocco, Alessio and Van Werkhoven, Ben},
	editor = {Carretero, Jesus and Shende, Sameer and Garcia-Blas, Javier and Brandic, Ivona and Olcoz, Katzalin and Schreiber, Martin},
	year = {2024},
	doi = {10.1007/978-3-031-69577-3_7},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {91--106},
}

@article{hijma2023optimization,
	title = {Optimization {Techniques} for {GPU} {Programming}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3570638},
	doi = {10.1145/3570638},
	abstract = {In the past decade, Graphics Processing Units have played an important role in the field of high-performance computing and they still advance new fields such as IoT, autonomous vehicles, and exascale computing. It is therefore important to understand how to extract performance from these processors, something that is not trivial. This survey discusses various optimization techniques found in 450 articles published in the last 14 years. We analyze the optimizations from different perspectives which shows that the various optimizations are highly interrelated, explaining the need for techniques such as auto-tuning.},
	language = {en},
	number = {11},
	urldate = {2024-04-29},
	journal = {ACM Computing Surveys},
	author = {Hijma, Pieter and Heldens, Stijn and Sclocco, Alessio and Van Werkhoven, Ben and Bal, Henri E.},
	month = nov,
	year = {2023},
	pages = {1--81},
}

@misc{PoetryPythonPackaging2023,
	title = {Poetry: {Python} packaging and dependency management made easy},
	copyright = {MIT},
	shorttitle = {Poetry},
	url = {https://github.com/python-poetry/poetry},
	abstract = {Poetry helps you declare, manage and install dependencies of Python projects, ensuring you have the right stack everywhere. Poetry replaces setup.py, requirements.txt, setup.cfg, MANIFEST.in and Pipfile with a simple pyproject.toml based project format.},
	urldate = {2023-09-13},
	publisher = {Poetry},
	author = {{Sébastien Eustace} and {Arun Babu Neelicattu}},
	month = sep,
	year = {2023},
	note = {original-date: 2018-02-28T15:23:47Z},
	keywords = {dependency-manager, package-manager, packaging, poetry, python},
}

@article{methodologyPaper,
	title = {A methodology for comparing optimization algorithms for auto-tuning},
	volume = {159},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X24002498},
	doi = {https://doi.org/10.1016/j.future.2024.05.021},
	abstract = {Adapting applications to optimally utilize available hardware is no mean feat: the plethora of choices for optimization techniques are infeasible to maximize manually. To this end, auto-tuning frameworks are used to automate this task, which in turn use optimization algorithms to efficiently search the vast searchspaces. However, there is a lack of comparability in studies presenting advances in auto-tuning frameworks and the optimization algorithms incorporated. As each publication varies in the way experiments are conducted, metrics used, and results reported, comparing the performance of optimization algorithms among publications is infeasible. The auto-tuning community identified this as a key challenge at the 2022 Lorentz Center workshop on auto-tuning. The examination of the current state of the practice in this paper further underlines this. We propose a community-driven methodology composed of four steps regarding experimental setup, tuning budget, dealing with stochasticity, and quantifying performance. This methodology builds upon similar methodologies in other fields while taking into account the constraints and specific characteristics of the auto-tuning field, resulting in novel techniques. The methodology is demonstrated in a simple case study that compares the performance of several optimization algorithms used to auto-tune CUDA kernels on a set of modern GPUs. We provide a software tool to make the application of the methodology easy for authors, and simplifies reproducibility of results.},
	journal = {Future Generation Computer Systems},
	author = {Willemsen, Floris-Jan and Schoonhoven, Richard and Filipovič, Jiří and Tørring, Jacob O. and van Nieuwpoort, Rob and van Werkhoven, Ben},
	year = {2024},
	keywords = {Auto-tuning, Methodology, Optimization algorithms, Performance comparison, Performance optimization},
	pages = {489--504},
}

@article{ytopt,
	title = {ytopt: {Autotuning} {Scientific} {Applications} for {Energy} {Efficiency} at {Large} {Scales}},
	issn = {1532-0626, 1532-0634},
	shorttitle = {ytopt},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/cpe.8322},
	doi = {10.1002/cpe.8322},
	abstract = {ABSTRACT
            As we enter the exascale computing era, efficiently utilizing power and optimizing the performance of scientific applications under power and energy constraints has become critical and challenging. We propose a low‐overhead autotuning framework to autotune performance and energy for various hybrid MPI/OpenMP scientific applications at large scales and to explore the tradeoffs between application runtime and power/energy for energy efficient application execution, then use this framework to autotune four ECP proxy applications—XSBench, AMG, SWFFT, and SW4lite. Our approach uses Bayesian optimization with a Random Forest surrogate model to effectively search parameter spaces with up to 6 million different configurations on two large‐scale HPC production systems, Theta at Argonne National Laboratory and Summit at Oak Ridge National Laboratory. The experimental results show that our autotuning framework at large scales has low overhead and achieves good scalability. Using the proposed autotuning framework to identify the best configurations, we achieve up to 91.59\% performance improvement, up to 21.2\% energy savings, and up to 37.84\% EDP (energy delay product) improvement on up to 4096 nodes.},
	language = {en},
	urldate = {2024-11-29},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Wu, Xingfu and Balaprakash, Prasanna and Kruse, Michael and Koo, Jaehoon and Videau, Brice and Hovland, Paul and Taylor, Valerie and Geltz, Brad and Jana, Siddhartha and Hall, Mary},
	month = oct,
	year = {2024},
	pages = {e8322},
}
